/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.aiplatform.v1.model;

/**
 * Config for importing RagFiles.
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the Vertex AI API. For a detailed explanation see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class GoogleCloudAiplatformV1ImportRagFilesConfig extends com.google.api.client.json.GenericJson {

  /**
   * Google Cloud Storage location. Supports importing individual files as well as entire Google
   * Cloud Storage directories. Sample formats: -
   * `gs://bucket_name/my_directory/object_name/my_file.txt` - `gs://bucket_name/my_directory`
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1GcsSource gcsSource;

  /**
   * Google Drive location. Supports importing individual files as well as Google Drive folders.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1GoogleDriveSource googleDriveSource;

  /**
   * Jira queries with their corresponding authentication.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1JiraSource jiraSource;

  /**
   * Optional. The max number of queries per minute that this job is allowed to make to the
   * embedding model specified on the corpus. This value is specific to this job and not shared
   * across other import jobs. Consult the Quotas page on the project to set an appropriate value
   * here. If unspecified, a default value of 1,000 QPM would be used.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Integer maxEmbeddingRequestsPerMin;

  /**
   * The BigQuery destination to write partial failures to. It should be a bigquery table resource
   * name (e.g. "bq://projectId.bqDatasetId.bqTableId"). The dataset must exist. If the table does
   * not exist, it will be created with the expected schema. If the table exists, the schema will be
   * validated and data will be added to this existing table. Deprecated. Prefer to use
   * `import_result_bq_sink`.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1BigQueryDestination partialFailureBigquerySink;

  /**
   * The Cloud Storage path to write partial failures to. Deprecated. Prefer to use
   * `import_result_gcs_sink`.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1GcsDestination partialFailureGcsSink;

  /**
   * Specifies the transformation config for RagFiles.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1RagFileTransformationConfig ragFileTransformationConfig;

  /**
   * SharePoint sources.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1SharePointSources sharePointSources;

  /**
   * Slack channels with their corresponding access tokens.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1SlackSource slackSource;

  /**
   * Google Cloud Storage location. Supports importing individual files as well as entire Google
   * Cloud Storage directories. Sample formats: -
   * `gs://bucket_name/my_directory/object_name/my_file.txt` - `gs://bucket_name/my_directory`
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1GcsSource getGcsSource() {
    return gcsSource;
  }

  /**
   * Google Cloud Storage location. Supports importing individual files as well as entire Google
   * Cloud Storage directories. Sample formats: -
   * `gs://bucket_name/my_directory/object_name/my_file.txt` - `gs://bucket_name/my_directory`
   * @param gcsSource gcsSource or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setGcsSource(GoogleCloudAiplatformV1GcsSource gcsSource) {
    this.gcsSource = gcsSource;
    return this;
  }

  /**
   * Google Drive location. Supports importing individual files as well as Google Drive folders.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1GoogleDriveSource getGoogleDriveSource() {
    return googleDriveSource;
  }

  /**
   * Google Drive location. Supports importing individual files as well as Google Drive folders.
   * @param googleDriveSource googleDriveSource or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setGoogleDriveSource(GoogleCloudAiplatformV1GoogleDriveSource googleDriveSource) {
    this.googleDriveSource = googleDriveSource;
    return this;
  }

  /**
   * Jira queries with their corresponding authentication.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1JiraSource getJiraSource() {
    return jiraSource;
  }

  /**
   * Jira queries with their corresponding authentication.
   * @param jiraSource jiraSource or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setJiraSource(GoogleCloudAiplatformV1JiraSource jiraSource) {
    this.jiraSource = jiraSource;
    return this;
  }

  /**
   * Optional. The max number of queries per minute that this job is allowed to make to the
   * embedding model specified on the corpus. This value is specific to this job and not shared
   * across other import jobs. Consult the Quotas page on the project to set an appropriate value
   * here. If unspecified, a default value of 1,000 QPM would be used.
   * @return value or {@code null} for none
   */
  public java.lang.Integer getMaxEmbeddingRequestsPerMin() {
    return maxEmbeddingRequestsPerMin;
  }

  /**
   * Optional. The max number of queries per minute that this job is allowed to make to the
   * embedding model specified on the corpus. This value is specific to this job and not shared
   * across other import jobs. Consult the Quotas page on the project to set an appropriate value
   * here. If unspecified, a default value of 1,000 QPM would be used.
   * @param maxEmbeddingRequestsPerMin maxEmbeddingRequestsPerMin or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setMaxEmbeddingRequestsPerMin(java.lang.Integer maxEmbeddingRequestsPerMin) {
    this.maxEmbeddingRequestsPerMin = maxEmbeddingRequestsPerMin;
    return this;
  }

  /**
   * The BigQuery destination to write partial failures to. It should be a bigquery table resource
   * name (e.g. "bq://projectId.bqDatasetId.bqTableId"). The dataset must exist. If the table does
   * not exist, it will be created with the expected schema. If the table exists, the schema will be
   * validated and data will be added to this existing table. Deprecated. Prefer to use
   * `import_result_bq_sink`.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1BigQueryDestination getPartialFailureBigquerySink() {
    return partialFailureBigquerySink;
  }

  /**
   * The BigQuery destination to write partial failures to. It should be a bigquery table resource
   * name (e.g. "bq://projectId.bqDatasetId.bqTableId"). The dataset must exist. If the table does
   * not exist, it will be created with the expected schema. If the table exists, the schema will be
   * validated and data will be added to this existing table. Deprecated. Prefer to use
   * `import_result_bq_sink`.
   * @param partialFailureBigquerySink partialFailureBigquerySink or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setPartialFailureBigquerySink(GoogleCloudAiplatformV1BigQueryDestination partialFailureBigquerySink) {
    this.partialFailureBigquerySink = partialFailureBigquerySink;
    return this;
  }

  /**
   * The Cloud Storage path to write partial failures to. Deprecated. Prefer to use
   * `import_result_gcs_sink`.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1GcsDestination getPartialFailureGcsSink() {
    return partialFailureGcsSink;
  }

  /**
   * The Cloud Storage path to write partial failures to. Deprecated. Prefer to use
   * `import_result_gcs_sink`.
   * @param partialFailureGcsSink partialFailureGcsSink or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setPartialFailureGcsSink(GoogleCloudAiplatformV1GcsDestination partialFailureGcsSink) {
    this.partialFailureGcsSink = partialFailureGcsSink;
    return this;
  }

  /**
   * Specifies the transformation config for RagFiles.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1RagFileTransformationConfig getRagFileTransformationConfig() {
    return ragFileTransformationConfig;
  }

  /**
   * Specifies the transformation config for RagFiles.
   * @param ragFileTransformationConfig ragFileTransformationConfig or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setRagFileTransformationConfig(GoogleCloudAiplatformV1RagFileTransformationConfig ragFileTransformationConfig) {
    this.ragFileTransformationConfig = ragFileTransformationConfig;
    return this;
  }

  /**
   * SharePoint sources.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1SharePointSources getSharePointSources() {
    return sharePointSources;
  }

  /**
   * SharePoint sources.
   * @param sharePointSources sharePointSources or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setSharePointSources(GoogleCloudAiplatformV1SharePointSources sharePointSources) {
    this.sharePointSources = sharePointSources;
    return this;
  }

  /**
   * Slack channels with their corresponding access tokens.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1SlackSource getSlackSource() {
    return slackSource;
  }

  /**
   * Slack channels with their corresponding access tokens.
   * @param slackSource slackSource or {@code null} for none
   */
  public GoogleCloudAiplatformV1ImportRagFilesConfig setSlackSource(GoogleCloudAiplatformV1SlackSource slackSource) {
    this.slackSource = slackSource;
    return this;
  }

  @Override
  public GoogleCloudAiplatformV1ImportRagFilesConfig set(String fieldName, Object value) {
    return (GoogleCloudAiplatformV1ImportRagFilesConfig) super.set(fieldName, value);
  }

  @Override
  public GoogleCloudAiplatformV1ImportRagFilesConfig clone() {
    return (GoogleCloudAiplatformV1ImportRagFilesConfig) super.clone();
  }

}
