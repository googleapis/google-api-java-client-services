/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.ml.v1.model;

/**
 * Represents a version of the model. Each version is a trained model deployed in the cloud, ready
 * to handle prediction requests. A model can have multiple versions. You can get information about
 * all of the versions of a given model by calling projects.models.versions.list.
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the AI Platform Training & Prediction API. For a detailed
 * explanation see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class GoogleCloudMlV1Version extends com.google.api.client.json.GenericJson {

  /**
   * Optional. Accelerator config for using GPUs for online prediction (beta). Only specify this
   * field if you have specified a Compute Engine (N1) machine type in the `machineType` field.
   * Learn more about [using GPUs for online prediction](/ml-engine/docs/machine-types-online-
   * prediction#gpus).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1AcceleratorConfig acceleratorConfig;

  /**
   * Automatically scale the number of nodes used to serve the model in response to increases and
   * decreases in traffic. Care should be taken to ramp up traffic according to the model's ability
   * to scale or you will start seeing increases in latency and 429 response codes. Note that you
   * cannot use AutoScaling if your version uses [GPUs](#Version.FIELDS.accelerator_config).
   * Instead, you must use specify `manual_scaling`.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1AutoScaling autoScaling;

  /**
   * Optional. Specifies a custom container to use for serving predictions. If you specify this
   * field, then `machineType` is required. If you specify this field, then `deploymentUri` is
   * optional. If you specify this field, then you must not specify `runtimeVersion`, `packageUris`,
   * `framework`, `pythonVersion`, or `predictionClass`.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1ContainerSpec container;

  /**
   * Output only. The time the version was created.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private String createTime;

  /**
   * The Cloud Storage URI of a directory containing trained model artifacts to be used to create
   * the model version. See the [guide to deploying models](/ai-platform/prediction/docs/deploying-
   * models) for more information. The total number of files under this directory must not exceed
   * 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the
   * specified directory to a location managed by the service. From then on, AI Platform Prediction
   * uses these copies of the model artifacts to serve predictions, not the original files in Cloud
   * Storage, so this location is useful only as a historical record. If you specify container, then
   * this field is optional. Otherwise, it is required. Learn [how to use this field with a custom
   * container](/ai-platform/prediction/docs/custom-container-requirements#artifacts).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String deploymentUri;

  /**
   * Optional. The description specified for the version when it was created.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String description;

  /**
   * Output only. The details of a failure or a cancellation.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String errorMessage;

  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates
   * of a model from overwriting each other. It is strongly suggested that systems make use of the
   * `etag` in the read-modify-write cycle to perform model updates in order to avoid race
   * conditions: An `etag` is returned in the response to `GetVersion`, and systems are expected to
   * put that etag in the request to `UpdateVersion` to ensure that their change will be applied to
   * the model as intended.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String etag;

  /**
   * Optional. Configures explainability features on the model's version. Some explanation features
   * require additional metadata to be loaded as part of the model payload.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1ExplanationConfig explanationConfig;

  /**
   * Optional. The machine learning framework AI Platform uses to train this version of the model.
   * Valid values are `TENSORFLOW`, `SCIKIT_LEARN`, `XGBOOST`. If you do not specify a framework, AI
   * Platform will analyze files in the deployment_uri to determine a framework. If you choose
   * `SCIKIT_LEARN` or `XGBOOST`, you must also set the runtime version of the model to 1.4 or
   * greater. Do **not** specify a framework if you're deploying a [custom prediction routine](/ai-
   * platform/prediction/docs/custom-prediction-routines) or if you're using a [custom container
   * ](/ai-platform/prediction/docs/use-custom-container).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String framework;

  /**
   * Output only. If true, this version will be used to handle prediction requests that do not
   * specify a version. You can change the default version by calling
   * projects.methods.versions.setDefault.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean isDefault;

  /**
   * Optional. One or more labels that you can add, to organize your model versions. Each label is a
   * key-value pair, where both the key and the value are arbitrary strings that you supply. For
   * more information, see the documentation on using labels.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.Map<String, java.lang.String> labels;

  /**
   * Output only. The time the version was last used for prediction.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private String lastUseTime;

  /**
   * Optional. The type of machine on which to serve the model. Currently only applies to online
   * prediction service. If this field is not specified, it defaults to `mls1-c1-m2`. Online
   * prediction supports the following machine types: * `mls1-c1-m2` * `mls1-c4-m2` *
   * `n1-standard-2` * `n1-standard-4` * `n1-standard-8` * `n1-standard-16` * `n1-standard-32` *
   * `n1-highmem-2` * `n1-highmem-4` * `n1-highmem-8` * `n1-highmem-16` * `n1-highmem-32` *
   * `n1-highcpu-2` * `n1-highcpu-4` * `n1-highcpu-8` * `n1-highcpu-16` * `n1-highcpu-32`
   * `mls1-c4-m2` is in beta. All other machine types are generally available. Learn more about the
   * [differences between machine types](/ml-engine/docs/machine-types-online-prediction).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String machineType;

  /**
   * Manually select the number of nodes to use for serving the model. You should generally use
   * `auto_scaling` with an appropriate `min_nodes` instead, but this option is available if you
   * want more predictable billing. Beware that latency and error rates will increase if the traffic
   * exceeds that capability of the system to serve it based on the selected number of nodes.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1ManualScaling manualScaling;

  /**
   * Required. The name specified for the version when it was created. The version name must be
   * unique within the model it is created in.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String name;

  /**
   * Optional. Cloud Storage paths (`gs://â€¦`) of packages for [custom prediction routines](/ml-
   * engine/docs/tensorflow/custom-prediction-routines) or [scikit-learn pipelines with custom code
   * ](/ml-engine/docs/scikit/exporting-for-prediction#custom-pipeline-code). For a custom
   * prediction routine, one of these packages must contain your Predictor class (see
   * [`predictionClass`](#Version.FIELDS.prediction_class)). Additionally, include any dependencies
   * used by your Predictor or scikit-learn pipeline uses that are not already included in your
   * selected [runtime version](/ml-engine/docs/tensorflow/runtime-version-list). If you specify
   * this field, you must also set [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or
   * greater.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<java.lang.String> packageUris;

  /**
   * Optional. The fully qualified name (module_name.class_name) of a class that implements the
   * Predictor interface described in this reference field. The module containing this class should
   * be included in a package provided to the [`packageUris` field](#Version.FIELDS.package_uris).
   * Specify this field if and only if you are deploying a [custom prediction routine (beta)](/ml-
   * engine/docs/tensorflow/custom-prediction-routines). If you specify this field, you must set
   * [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or greater and you must set
   * `machineType` to a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-
   * prediction). The following code sample provides the Predictor interface: class
   * Predictor(object): Interface for constructing custom predictors. def predict(self, instances,
   * **kwargs): Performs custom prediction. Instances are the decoded values from the request. They
   * have already been deserialized from JSON. Args: instances: A list of prediction input
   * instances. **kwargs: A dictionary of keyword args provided as additional fields on the predict
   * request body. Returns: A list of outputs containing the prediction results. This list must be
   * JSON serializable.  raise NotImplementedError() @classmethod def from_path(cls, model_dir):
   * Creates an instance of Predictor using the given path. Loading of the predictor should be done
   * in this method. Args: model_dir: The local directory that contains the exported model file
   * along with any additional files uploaded when creating the version resource. Returns: An
   * instance implementing this Predictor class.  raise NotImplementedError() Learn more about [the
   * Predictor interface and custom prediction routines](/ml-engine/docs/tensorflow/custom-
   * prediction-routines).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String predictionClass;

  /**
   * Required. The version of Python used in prediction. The following Python versions are
   * available: * Python '3.7' is available when `runtime_version` is set to '1.15' or later. *
   * Python '3.5' is available when `runtime_version` is set to a version from '1.4' to '1.14'. *
   * Python '2.7' is available when `runtime_version` is set to '1.15' or earlier. Read more about
   * the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String pythonVersion;

  /**
   * Optional. *Only* specify this field in a projects.models.versions.patch request. Specifying it
   * in a projects.models.versions.create request has no effect. Configures the request-response
   * pair logging on predictions from this Version.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1RequestLoggingConfig requestLoggingConfig;

  /**
   * Optional. Specifies paths on a custom container's HTTP server where AI Platform Prediction
   * sends certain requests. If you specify this field, then you must also specify the `container`
   * field. If you specify the `container` field and do not specify this field, it defaults to the
   * following: ```json { "predict": "/v1/models/MODEL/versions/VERSION:predict", "health":
   * "/v1/models/MODEL/versions/VERSION" } ``` See RouteMap for more details about these default
   * values.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudMlV1RouteMap routes;

  /**
   * Required. The AI Platform runtime version to use for this deployment. For more information, see
   * the [runtime version list](/ml-engine/docs/runtime-version-list) and [how to manage runtime
   * versions](/ml-engine/docs/versioning).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String runtimeVersion;

  /**
   * Optional. Specifies the service account for resource access control. If you specify this field,
   * then you must also specify either the `containerSpec` or the `predictionClass` field. Learn
   * more about [using a custom service account](/ai-platform/prediction/docs/custom-service-
   * account).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String serviceAccount;

  /**
   * Output only. The state of a version.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String state;

  /**
   * Optional. Accelerator config for using GPUs for online prediction (beta). Only specify this
   * field if you have specified a Compute Engine (N1) machine type in the `machineType` field.
   * Learn more about [using GPUs for online prediction](/ml-engine/docs/machine-types-online-
   * prediction#gpus).
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1AcceleratorConfig getAcceleratorConfig() {
    return acceleratorConfig;
  }

  /**
   * Optional. Accelerator config for using GPUs for online prediction (beta). Only specify this
   * field if you have specified a Compute Engine (N1) machine type in the `machineType` field.
   * Learn more about [using GPUs for online prediction](/ml-engine/docs/machine-types-online-
   * prediction#gpus).
   * @param acceleratorConfig acceleratorConfig or {@code null} for none
   */
  public GoogleCloudMlV1Version setAcceleratorConfig(GoogleCloudMlV1AcceleratorConfig acceleratorConfig) {
    this.acceleratorConfig = acceleratorConfig;
    return this;
  }

  /**
   * Automatically scale the number of nodes used to serve the model in response to increases and
   * decreases in traffic. Care should be taken to ramp up traffic according to the model's ability
   * to scale or you will start seeing increases in latency and 429 response codes. Note that you
   * cannot use AutoScaling if your version uses [GPUs](#Version.FIELDS.accelerator_config).
   * Instead, you must use specify `manual_scaling`.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1AutoScaling getAutoScaling() {
    return autoScaling;
  }

  /**
   * Automatically scale the number of nodes used to serve the model in response to increases and
   * decreases in traffic. Care should be taken to ramp up traffic according to the model's ability
   * to scale or you will start seeing increases in latency and 429 response codes. Note that you
   * cannot use AutoScaling if your version uses [GPUs](#Version.FIELDS.accelerator_config).
   * Instead, you must use specify `manual_scaling`.
   * @param autoScaling autoScaling or {@code null} for none
   */
  public GoogleCloudMlV1Version setAutoScaling(GoogleCloudMlV1AutoScaling autoScaling) {
    this.autoScaling = autoScaling;
    return this;
  }

  /**
   * Optional. Specifies a custom container to use for serving predictions. If you specify this
   * field, then `machineType` is required. If you specify this field, then `deploymentUri` is
   * optional. If you specify this field, then you must not specify `runtimeVersion`, `packageUris`,
   * `framework`, `pythonVersion`, or `predictionClass`.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1ContainerSpec getContainer() {
    return container;
  }

  /**
   * Optional. Specifies a custom container to use for serving predictions. If you specify this
   * field, then `machineType` is required. If you specify this field, then `deploymentUri` is
   * optional. If you specify this field, then you must not specify `runtimeVersion`, `packageUris`,
   * `framework`, `pythonVersion`, or `predictionClass`.
   * @param container container or {@code null} for none
   */
  public GoogleCloudMlV1Version setContainer(GoogleCloudMlV1ContainerSpec container) {
    this.container = container;
    return this;
  }

  /**
   * Output only. The time the version was created.
   * @return value or {@code null} for none
   */
  public String getCreateTime() {
    return createTime;
  }

  /**
   * Output only. The time the version was created.
   * @param createTime createTime or {@code null} for none
   */
  public GoogleCloudMlV1Version setCreateTime(String createTime) {
    this.createTime = createTime;
    return this;
  }

  /**
   * The Cloud Storage URI of a directory containing trained model artifacts to be used to create
   * the model version. See the [guide to deploying models](/ai-platform/prediction/docs/deploying-
   * models) for more information. The total number of files under this directory must not exceed
   * 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the
   * specified directory to a location managed by the service. From then on, AI Platform Prediction
   * uses these copies of the model artifacts to serve predictions, not the original files in Cloud
   * Storage, so this location is useful only as a historical record. If you specify container, then
   * this field is optional. Otherwise, it is required. Learn [how to use this field with a custom
   * container](/ai-platform/prediction/docs/custom-container-requirements#artifacts).
   * @return value or {@code null} for none
   */
  public java.lang.String getDeploymentUri() {
    return deploymentUri;
  }

  /**
   * The Cloud Storage URI of a directory containing trained model artifacts to be used to create
   * the model version. See the [guide to deploying models](/ai-platform/prediction/docs/deploying-
   * models) for more information. The total number of files under this directory must not exceed
   * 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the
   * specified directory to a location managed by the service. From then on, AI Platform Prediction
   * uses these copies of the model artifacts to serve predictions, not the original files in Cloud
   * Storage, so this location is useful only as a historical record. If you specify container, then
   * this field is optional. Otherwise, it is required. Learn [how to use this field with a custom
   * container](/ai-platform/prediction/docs/custom-container-requirements#artifacts).
   * @param deploymentUri deploymentUri or {@code null} for none
   */
  public GoogleCloudMlV1Version setDeploymentUri(java.lang.String deploymentUri) {
    this.deploymentUri = deploymentUri;
    return this;
  }

  /**
   * Optional. The description specified for the version when it was created.
   * @return value or {@code null} for none
   */
  public java.lang.String getDescription() {
    return description;
  }

  /**
   * Optional. The description specified for the version when it was created.
   * @param description description or {@code null} for none
   */
  public GoogleCloudMlV1Version setDescription(java.lang.String description) {
    this.description = description;
    return this;
  }

  /**
   * Output only. The details of a failure or a cancellation.
   * @return value or {@code null} for none
   */
  public java.lang.String getErrorMessage() {
    return errorMessage;
  }

  /**
   * Output only. The details of a failure or a cancellation.
   * @param errorMessage errorMessage or {@code null} for none
   */
  public GoogleCloudMlV1Version setErrorMessage(java.lang.String errorMessage) {
    this.errorMessage = errorMessage;
    return this;
  }

  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates
   * of a model from overwriting each other. It is strongly suggested that systems make use of the
   * `etag` in the read-modify-write cycle to perform model updates in order to avoid race
   * conditions: An `etag` is returned in the response to `GetVersion`, and systems are expected to
   * put that etag in the request to `UpdateVersion` to ensure that their change will be applied to
   * the model as intended.
   * @see #decodeEtag()
   * @return value or {@code null} for none
   */
  public java.lang.String getEtag() {
    return etag;
  }

  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates
   * of a model from overwriting each other. It is strongly suggested that systems make use of the
   * `etag` in the read-modify-write cycle to perform model updates in order to avoid race
   * conditions: An `etag` is returned in the response to `GetVersion`, and systems are expected to
   * put that etag in the request to `UpdateVersion` to ensure that their change will be applied to
   * the model as intended.
   * @see #getEtag()
   * @return Base64 decoded value or {@code null} for none
   *
   * @since 1.14
   */
  public byte[] decodeEtag() {
    return com.google.api.client.util.Base64.decodeBase64(etag);
  }

  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates
   * of a model from overwriting each other. It is strongly suggested that systems make use of the
   * `etag` in the read-modify-write cycle to perform model updates in order to avoid race
   * conditions: An `etag` is returned in the response to `GetVersion`, and systems are expected to
   * put that etag in the request to `UpdateVersion` to ensure that their change will be applied to
   * the model as intended.
   * @see #encodeEtag()
   * @param etag etag or {@code null} for none
   */
  public GoogleCloudMlV1Version setEtag(java.lang.String etag) {
    this.etag = etag;
    return this;
  }

  /**
   * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates
   * of a model from overwriting each other. It is strongly suggested that systems make use of the
   * `etag` in the read-modify-write cycle to perform model updates in order to avoid race
   * conditions: An `etag` is returned in the response to `GetVersion`, and systems are expected to
   * put that etag in the request to `UpdateVersion` to ensure that their change will be applied to
   * the model as intended.
   * @see #setEtag()
   *
   * <p>
   * The value is encoded Base64 or {@code null} for none.
   * </p>
   *
   * @since 1.14
   */
  public GoogleCloudMlV1Version encodeEtag(byte[] etag) {
    this.etag = com.google.api.client.util.Base64.encodeBase64URLSafeString(etag);
    return this;
  }

  /**
   * Optional. Configures explainability features on the model's version. Some explanation features
   * require additional metadata to be loaded as part of the model payload.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1ExplanationConfig getExplanationConfig() {
    return explanationConfig;
  }

  /**
   * Optional. Configures explainability features on the model's version. Some explanation features
   * require additional metadata to be loaded as part of the model payload.
   * @param explanationConfig explanationConfig or {@code null} for none
   */
  public GoogleCloudMlV1Version setExplanationConfig(GoogleCloudMlV1ExplanationConfig explanationConfig) {
    this.explanationConfig = explanationConfig;
    return this;
  }

  /**
   * Optional. The machine learning framework AI Platform uses to train this version of the model.
   * Valid values are `TENSORFLOW`, `SCIKIT_LEARN`, `XGBOOST`. If you do not specify a framework, AI
   * Platform will analyze files in the deployment_uri to determine a framework. If you choose
   * `SCIKIT_LEARN` or `XGBOOST`, you must also set the runtime version of the model to 1.4 or
   * greater. Do **not** specify a framework if you're deploying a [custom prediction routine](/ai-
   * platform/prediction/docs/custom-prediction-routines) or if you're using a [custom container
   * ](/ai-platform/prediction/docs/use-custom-container).
   * @return value or {@code null} for none
   */
  public java.lang.String getFramework() {
    return framework;
  }

  /**
   * Optional. The machine learning framework AI Platform uses to train this version of the model.
   * Valid values are `TENSORFLOW`, `SCIKIT_LEARN`, `XGBOOST`. If you do not specify a framework, AI
   * Platform will analyze files in the deployment_uri to determine a framework. If you choose
   * `SCIKIT_LEARN` or `XGBOOST`, you must also set the runtime version of the model to 1.4 or
   * greater. Do **not** specify a framework if you're deploying a [custom prediction routine](/ai-
   * platform/prediction/docs/custom-prediction-routines) or if you're using a [custom container
   * ](/ai-platform/prediction/docs/use-custom-container).
   * @param framework framework or {@code null} for none
   */
  public GoogleCloudMlV1Version setFramework(java.lang.String framework) {
    this.framework = framework;
    return this;
  }

  /**
   * Output only. If true, this version will be used to handle prediction requests that do not
   * specify a version. You can change the default version by calling
   * projects.methods.versions.setDefault.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getIsDefault() {
    return isDefault;
  }

  /**
   * Output only. If true, this version will be used to handle prediction requests that do not
   * specify a version. You can change the default version by calling
   * projects.methods.versions.setDefault.
   * @param isDefault isDefault or {@code null} for none
   */
  public GoogleCloudMlV1Version setIsDefault(java.lang.Boolean isDefault) {
    this.isDefault = isDefault;
    return this;
  }

  /**
   * Optional. One or more labels that you can add, to organize your model versions. Each label is a
   * key-value pair, where both the key and the value are arbitrary strings that you supply. For
   * more information, see the documentation on using labels.
   * @return value or {@code null} for none
   */
  public java.util.Map<String, java.lang.String> getLabels() {
    return labels;
  }

  /**
   * Optional. One or more labels that you can add, to organize your model versions. Each label is a
   * key-value pair, where both the key and the value are arbitrary strings that you supply. For
   * more information, see the documentation on using labels.
   * @param labels labels or {@code null} for none
   */
  public GoogleCloudMlV1Version setLabels(java.util.Map<String, java.lang.String> labels) {
    this.labels = labels;
    return this;
  }

  /**
   * Output only. The time the version was last used for prediction.
   * @return value or {@code null} for none
   */
  public String getLastUseTime() {
    return lastUseTime;
  }

  /**
   * Output only. The time the version was last used for prediction.
   * @param lastUseTime lastUseTime or {@code null} for none
   */
  public GoogleCloudMlV1Version setLastUseTime(String lastUseTime) {
    this.lastUseTime = lastUseTime;
    return this;
  }

  /**
   * Optional. The type of machine on which to serve the model. Currently only applies to online
   * prediction service. If this field is not specified, it defaults to `mls1-c1-m2`. Online
   * prediction supports the following machine types: * `mls1-c1-m2` * `mls1-c4-m2` *
   * `n1-standard-2` * `n1-standard-4` * `n1-standard-8` * `n1-standard-16` * `n1-standard-32` *
   * `n1-highmem-2` * `n1-highmem-4` * `n1-highmem-8` * `n1-highmem-16` * `n1-highmem-32` *
   * `n1-highcpu-2` * `n1-highcpu-4` * `n1-highcpu-8` * `n1-highcpu-16` * `n1-highcpu-32`
   * `mls1-c4-m2` is in beta. All other machine types are generally available. Learn more about the
   * [differences between machine types](/ml-engine/docs/machine-types-online-prediction).
   * @return value or {@code null} for none
   */
  public java.lang.String getMachineType() {
    return machineType;
  }

  /**
   * Optional. The type of machine on which to serve the model. Currently only applies to online
   * prediction service. If this field is not specified, it defaults to `mls1-c1-m2`. Online
   * prediction supports the following machine types: * `mls1-c1-m2` * `mls1-c4-m2` *
   * `n1-standard-2` * `n1-standard-4` * `n1-standard-8` * `n1-standard-16` * `n1-standard-32` *
   * `n1-highmem-2` * `n1-highmem-4` * `n1-highmem-8` * `n1-highmem-16` * `n1-highmem-32` *
   * `n1-highcpu-2` * `n1-highcpu-4` * `n1-highcpu-8` * `n1-highcpu-16` * `n1-highcpu-32`
   * `mls1-c4-m2` is in beta. All other machine types are generally available. Learn more about the
   * [differences between machine types](/ml-engine/docs/machine-types-online-prediction).
   * @param machineType machineType or {@code null} for none
   */
  public GoogleCloudMlV1Version setMachineType(java.lang.String machineType) {
    this.machineType = machineType;
    return this;
  }

  /**
   * Manually select the number of nodes to use for serving the model. You should generally use
   * `auto_scaling` with an appropriate `min_nodes` instead, but this option is available if you
   * want more predictable billing. Beware that latency and error rates will increase if the traffic
   * exceeds that capability of the system to serve it based on the selected number of nodes.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1ManualScaling getManualScaling() {
    return manualScaling;
  }

  /**
   * Manually select the number of nodes to use for serving the model. You should generally use
   * `auto_scaling` with an appropriate `min_nodes` instead, but this option is available if you
   * want more predictable billing. Beware that latency and error rates will increase if the traffic
   * exceeds that capability of the system to serve it based on the selected number of nodes.
   * @param manualScaling manualScaling or {@code null} for none
   */
  public GoogleCloudMlV1Version setManualScaling(GoogleCloudMlV1ManualScaling manualScaling) {
    this.manualScaling = manualScaling;
    return this;
  }

  /**
   * Required. The name specified for the version when it was created. The version name must be
   * unique within the model it is created in.
   * @return value or {@code null} for none
   */
  public java.lang.String getName() {
    return name;
  }

  /**
   * Required. The name specified for the version when it was created. The version name must be
   * unique within the model it is created in.
   * @param name name or {@code null} for none
   */
  public GoogleCloudMlV1Version setName(java.lang.String name) {
    this.name = name;
    return this;
  }

  /**
   * Optional. Cloud Storage paths (`gs://â€¦`) of packages for [custom prediction routines](/ml-
   * engine/docs/tensorflow/custom-prediction-routines) or [scikit-learn pipelines with custom code
   * ](/ml-engine/docs/scikit/exporting-for-prediction#custom-pipeline-code). For a custom
   * prediction routine, one of these packages must contain your Predictor class (see
   * [`predictionClass`](#Version.FIELDS.prediction_class)). Additionally, include any dependencies
   * used by your Predictor or scikit-learn pipeline uses that are not already included in your
   * selected [runtime version](/ml-engine/docs/tensorflow/runtime-version-list). If you specify
   * this field, you must also set [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or
   * greater.
   * @return value or {@code null} for none
   */
  public java.util.List<java.lang.String> getPackageUris() {
    return packageUris;
  }

  /**
   * Optional. Cloud Storage paths (`gs://â€¦`) of packages for [custom prediction routines](/ml-
   * engine/docs/tensorflow/custom-prediction-routines) or [scikit-learn pipelines with custom code
   * ](/ml-engine/docs/scikit/exporting-for-prediction#custom-pipeline-code). For a custom
   * prediction routine, one of these packages must contain your Predictor class (see
   * [`predictionClass`](#Version.FIELDS.prediction_class)). Additionally, include any dependencies
   * used by your Predictor or scikit-learn pipeline uses that are not already included in your
   * selected [runtime version](/ml-engine/docs/tensorflow/runtime-version-list). If you specify
   * this field, you must also set [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or
   * greater.
   * @param packageUris packageUris or {@code null} for none
   */
  public GoogleCloudMlV1Version setPackageUris(java.util.List<java.lang.String> packageUris) {
    this.packageUris = packageUris;
    return this;
  }

  /**
   * Optional. The fully qualified name (module_name.class_name) of a class that implements the
   * Predictor interface described in this reference field. The module containing this class should
   * be included in a package provided to the [`packageUris` field](#Version.FIELDS.package_uris).
   * Specify this field if and only if you are deploying a [custom prediction routine (beta)](/ml-
   * engine/docs/tensorflow/custom-prediction-routines). If you specify this field, you must set
   * [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or greater and you must set
   * `machineType` to a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-
   * prediction). The following code sample provides the Predictor interface: class
   * Predictor(object): Interface for constructing custom predictors. def predict(self, instances,
   * **kwargs): Performs custom prediction. Instances are the decoded values from the request. They
   * have already been deserialized from JSON. Args: instances: A list of prediction input
   * instances. **kwargs: A dictionary of keyword args provided as additional fields on the predict
   * request body. Returns: A list of outputs containing the prediction results. This list must be
   * JSON serializable.  raise NotImplementedError() @classmethod def from_path(cls, model_dir):
   * Creates an instance of Predictor using the given path. Loading of the predictor should be done
   * in this method. Args: model_dir: The local directory that contains the exported model file
   * along with any additional files uploaded when creating the version resource. Returns: An
   * instance implementing this Predictor class.  raise NotImplementedError() Learn more about [the
   * Predictor interface and custom prediction routines](/ml-engine/docs/tensorflow/custom-
   * prediction-routines).
   * @return value or {@code null} for none
   */
  public java.lang.String getPredictionClass() {
    return predictionClass;
  }

  /**
   * Optional. The fully qualified name (module_name.class_name) of a class that implements the
   * Predictor interface described in this reference field. The module containing this class should
   * be included in a package provided to the [`packageUris` field](#Version.FIELDS.package_uris).
   * Specify this field if and only if you are deploying a [custom prediction routine (beta)](/ml-
   * engine/docs/tensorflow/custom-prediction-routines). If you specify this field, you must set
   * [`runtimeVersion`](#Version.FIELDS.runtime_version) to 1.4 or greater and you must set
   * `machineType` to a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-
   * prediction). The following code sample provides the Predictor interface: class
   * Predictor(object): Interface for constructing custom predictors. def predict(self, instances,
   * **kwargs): Performs custom prediction. Instances are the decoded values from the request. They
   * have already been deserialized from JSON. Args: instances: A list of prediction input
   * instances. **kwargs: A dictionary of keyword args provided as additional fields on the predict
   * request body. Returns: A list of outputs containing the prediction results. This list must be
   * JSON serializable.  raise NotImplementedError() @classmethod def from_path(cls, model_dir):
   * Creates an instance of Predictor using the given path. Loading of the predictor should be done
   * in this method. Args: model_dir: The local directory that contains the exported model file
   * along with any additional files uploaded when creating the version resource. Returns: An
   * instance implementing this Predictor class.  raise NotImplementedError() Learn more about [the
   * Predictor interface and custom prediction routines](/ml-engine/docs/tensorflow/custom-
   * prediction-routines).
   * @param predictionClass predictionClass or {@code null} for none
   */
  public GoogleCloudMlV1Version setPredictionClass(java.lang.String predictionClass) {
    this.predictionClass = predictionClass;
    return this;
  }

  /**
   * Required. The version of Python used in prediction. The following Python versions are
   * available: * Python '3.7' is available when `runtime_version` is set to '1.15' or later. *
   * Python '3.5' is available when `runtime_version` is set to a version from '1.4' to '1.14'. *
   * Python '2.7' is available when `runtime_version` is set to '1.15' or earlier. Read more about
   * the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
   * @return value or {@code null} for none
   */
  public java.lang.String getPythonVersion() {
    return pythonVersion;
  }

  /**
   * Required. The version of Python used in prediction. The following Python versions are
   * available: * Python '3.7' is available when `runtime_version` is set to '1.15' or later. *
   * Python '3.5' is available when `runtime_version` is set to a version from '1.4' to '1.14'. *
   * Python '2.7' is available when `runtime_version` is set to '1.15' or earlier. Read more about
   * the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
   * @param pythonVersion pythonVersion or {@code null} for none
   */
  public GoogleCloudMlV1Version setPythonVersion(java.lang.String pythonVersion) {
    this.pythonVersion = pythonVersion;
    return this;
  }

  /**
   * Optional. *Only* specify this field in a projects.models.versions.patch request. Specifying it
   * in a projects.models.versions.create request has no effect. Configures the request-response
   * pair logging on predictions from this Version.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1RequestLoggingConfig getRequestLoggingConfig() {
    return requestLoggingConfig;
  }

  /**
   * Optional. *Only* specify this field in a projects.models.versions.patch request. Specifying it
   * in a projects.models.versions.create request has no effect. Configures the request-response
   * pair logging on predictions from this Version.
   * @param requestLoggingConfig requestLoggingConfig or {@code null} for none
   */
  public GoogleCloudMlV1Version setRequestLoggingConfig(GoogleCloudMlV1RequestLoggingConfig requestLoggingConfig) {
    this.requestLoggingConfig = requestLoggingConfig;
    return this;
  }

  /**
   * Optional. Specifies paths on a custom container's HTTP server where AI Platform Prediction
   * sends certain requests. If you specify this field, then you must also specify the `container`
   * field. If you specify the `container` field and do not specify this field, it defaults to the
   * following: ```json { "predict": "/v1/models/MODEL/versions/VERSION:predict", "health":
   * "/v1/models/MODEL/versions/VERSION" } ``` See RouteMap for more details about these default
   * values.
   * @return value or {@code null} for none
   */
  public GoogleCloudMlV1RouteMap getRoutes() {
    return routes;
  }

  /**
   * Optional. Specifies paths on a custom container's HTTP server where AI Platform Prediction
   * sends certain requests. If you specify this field, then you must also specify the `container`
   * field. If you specify the `container` field and do not specify this field, it defaults to the
   * following: ```json { "predict": "/v1/models/MODEL/versions/VERSION:predict", "health":
   * "/v1/models/MODEL/versions/VERSION" } ``` See RouteMap for more details about these default
   * values.
   * @param routes routes or {@code null} for none
   */
  public GoogleCloudMlV1Version setRoutes(GoogleCloudMlV1RouteMap routes) {
    this.routes = routes;
    return this;
  }

  /**
   * Required. The AI Platform runtime version to use for this deployment. For more information, see
   * the [runtime version list](/ml-engine/docs/runtime-version-list) and [how to manage runtime
   * versions](/ml-engine/docs/versioning).
   * @return value or {@code null} for none
   */
  public java.lang.String getRuntimeVersion() {
    return runtimeVersion;
  }

  /**
   * Required. The AI Platform runtime version to use for this deployment. For more information, see
   * the [runtime version list](/ml-engine/docs/runtime-version-list) and [how to manage runtime
   * versions](/ml-engine/docs/versioning).
   * @param runtimeVersion runtimeVersion or {@code null} for none
   */
  public GoogleCloudMlV1Version setRuntimeVersion(java.lang.String runtimeVersion) {
    this.runtimeVersion = runtimeVersion;
    return this;
  }

  /**
   * Optional. Specifies the service account for resource access control. If you specify this field,
   * then you must also specify either the `containerSpec` or the `predictionClass` field. Learn
   * more about [using a custom service account](/ai-platform/prediction/docs/custom-service-
   * account).
   * @return value or {@code null} for none
   */
  public java.lang.String getServiceAccount() {
    return serviceAccount;
  }

  /**
   * Optional. Specifies the service account for resource access control. If you specify this field,
   * then you must also specify either the `containerSpec` or the `predictionClass` field. Learn
   * more about [using a custom service account](/ai-platform/prediction/docs/custom-service-
   * account).
   * @param serviceAccount serviceAccount or {@code null} for none
   */
  public GoogleCloudMlV1Version setServiceAccount(java.lang.String serviceAccount) {
    this.serviceAccount = serviceAccount;
    return this;
  }

  /**
   * Output only. The state of a version.
   * @return value or {@code null} for none
   */
  public java.lang.String getState() {
    return state;
  }

  /**
   * Output only. The state of a version.
   * @param state state or {@code null} for none
   */
  public GoogleCloudMlV1Version setState(java.lang.String state) {
    this.state = state;
    return this;
  }

  @Override
  public GoogleCloudMlV1Version set(String fieldName, Object value) {
    return (GoogleCloudMlV1Version) super.set(fieldName, value);
  }

  @Override
  public GoogleCloudMlV1Version clone() {
    return (GoogleCloudMlV1Version) super.clone();
  }

}
