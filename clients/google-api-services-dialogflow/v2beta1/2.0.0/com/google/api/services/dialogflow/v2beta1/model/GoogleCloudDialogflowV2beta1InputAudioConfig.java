/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.dialogflow.v2beta1.model;

/**
 * Instructs the speech recognizer on how to process the audio content.
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the Dialogflow API. For a detailed explanation see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class GoogleCloudDialogflowV2beta1InputAudioConfig extends com.google.api.client.json.GenericJson {

  /**
   * Required. Audio encoding of the audio content to process.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String audioEncoding;

  /**
   * Configuration of barge-in behavior during the streaming of input audio.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudDialogflowV2beta1BargeInConfig bargeInConfig;

  /**
   * If set, use this no-speech timeout when the agent does not provide a no-speech timeout itself.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private String defaultNoSpeechTimeout;

  /**
   * Only used in Participants.AnalyzeContent and Participants.StreamingAnalyzeContent. If `false`
   * and recognition doesn't return any result, trigger `NO_SPEECH_RECOGNIZED` event to Dialogflow
   * agent.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean disableNoSpeechRecognizedEvent;

  /**
   * Enable automatic punctuation option at the speech backend.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean enableAutomaticPunctuation;

  /**
   * If `true`, Dialogflow returns SpeechWordInfo in StreamingRecognitionResult with information
   * about the recognized speech words, e.g. start and end time offsets. If false or unspecified,
   * Speech doesn't return any word-level information.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean enableWordInfo;

  /**
   * Required. The language of the supplied audio. Dialogflow does not do translations. See
   * [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of
   * the currently supported language codes. Note that queries in the same session do not
   * necessarily need to specify the same language. If not set, the language is inferred from the
   * ConversationProfile.stt_config.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String languageCode;

  /**
   * Optional. Which Speech model to select for the given request. For more information, see [Speech
   * models](https://cloud.google.com/dialogflow/es/docs/speech-models).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String model;

  /**
   * Which variant of the Speech model to use.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String modelVariant;

  /**
   * If `true`, the request will opt out for STT conformer model migration. This field will be
   * deprecated once force migration takes place in June 2024. Please refer to [Dialogflow ES Speech
   * model migration](https://cloud.google.com/dialogflow/es/docs/speech-model-migration).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean optOutConformerModelMigration;

  /**
   * A list of strings containing words and phrases that the speech recognizer should recognize with
   * higher likelihood. See [the Cloud Speech documentation](https://cloud.google.com/speech-to-
   * text/docs/basics#phrase-hints) for more details. This field is deprecated. Please use
   * [`speech_contexts`]() instead. If you specify both [`phrase_hints`]() and
   * [`speech_contexts`](), Dialogflow will treat the [`phrase_hints`]() as a single additional
   * [`SpeechContext`]().
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<java.lang.String> phraseHints;

  /**
   * A collection of phrase set resources to use for speech adaptation.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<java.lang.String> phraseSets;

  /**
   * Required. Sample rate (in Hertz) of the audio content sent in the query. Refer to [Cloud Speech
   * API documentation](https://cloud.google.com/speech-to-text/docs/basics) for more details.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Integer sampleRateHertz;

  /**
   * If `false` (default), recognition does not cease until the client closes the stream. If `true`,
   * the recognizer will detect a single spoken utterance in input audio. Recognition ceases when it
   * detects the audio's voice has stopped or paused. In this case, once a detected intent is
   * received, the client should close the stream and start a new request with a new stream as
   * needed. Note: This setting is relevant only for streaming methods. Note: When specified,
   * InputAudioConfig.single_utterance takes precedence over
   * StreamingDetectIntentRequest.single_utterance.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean singleUtterance;

  /**
   * Context information to assist speech recognition. See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints) for more
   * details.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<GoogleCloudDialogflowV2beta1SpeechContext> speechContexts;

  /**
   * Required. Audio encoding of the audio content to process.
   * @return value or {@code null} for none
   */
  public java.lang.String getAudioEncoding() {
    return audioEncoding;
  }

  /**
   * Required. Audio encoding of the audio content to process.
   * @param audioEncoding audioEncoding or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setAudioEncoding(java.lang.String audioEncoding) {
    this.audioEncoding = audioEncoding;
    return this;
  }

  /**
   * Configuration of barge-in behavior during the streaming of input audio.
   * @return value or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1BargeInConfig getBargeInConfig() {
    return bargeInConfig;
  }

  /**
   * Configuration of barge-in behavior during the streaming of input audio.
   * @param bargeInConfig bargeInConfig or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setBargeInConfig(GoogleCloudDialogflowV2beta1BargeInConfig bargeInConfig) {
    this.bargeInConfig = bargeInConfig;
    return this;
  }

  /**
   * If set, use this no-speech timeout when the agent does not provide a no-speech timeout itself.
   * @return value or {@code null} for none
   */
  public String getDefaultNoSpeechTimeout() {
    return defaultNoSpeechTimeout;
  }

  /**
   * If set, use this no-speech timeout when the agent does not provide a no-speech timeout itself.
   * @param defaultNoSpeechTimeout defaultNoSpeechTimeout or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setDefaultNoSpeechTimeout(String defaultNoSpeechTimeout) {
    this.defaultNoSpeechTimeout = defaultNoSpeechTimeout;
    return this;
  }

  /**
   * Only used in Participants.AnalyzeContent and Participants.StreamingAnalyzeContent. If `false`
   * and recognition doesn't return any result, trigger `NO_SPEECH_RECOGNIZED` event to Dialogflow
   * agent.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getDisableNoSpeechRecognizedEvent() {
    return disableNoSpeechRecognizedEvent;
  }

  /**
   * Only used in Participants.AnalyzeContent and Participants.StreamingAnalyzeContent. If `false`
   * and recognition doesn't return any result, trigger `NO_SPEECH_RECOGNIZED` event to Dialogflow
   * agent.
   * @param disableNoSpeechRecognizedEvent disableNoSpeechRecognizedEvent or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setDisableNoSpeechRecognizedEvent(java.lang.Boolean disableNoSpeechRecognizedEvent) {
    this.disableNoSpeechRecognizedEvent = disableNoSpeechRecognizedEvent;
    return this;
  }

  /**
   * Enable automatic punctuation option at the speech backend.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getEnableAutomaticPunctuation() {
    return enableAutomaticPunctuation;
  }

  /**
   * Enable automatic punctuation option at the speech backend.
   * @param enableAutomaticPunctuation enableAutomaticPunctuation or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setEnableAutomaticPunctuation(java.lang.Boolean enableAutomaticPunctuation) {
    this.enableAutomaticPunctuation = enableAutomaticPunctuation;
    return this;
  }

  /**
   * If `true`, Dialogflow returns SpeechWordInfo in StreamingRecognitionResult with information
   * about the recognized speech words, e.g. start and end time offsets. If false or unspecified,
   * Speech doesn't return any word-level information.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getEnableWordInfo() {
    return enableWordInfo;
  }

  /**
   * If `true`, Dialogflow returns SpeechWordInfo in StreamingRecognitionResult with information
   * about the recognized speech words, e.g. start and end time offsets. If false or unspecified,
   * Speech doesn't return any word-level information.
   * @param enableWordInfo enableWordInfo or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setEnableWordInfo(java.lang.Boolean enableWordInfo) {
    this.enableWordInfo = enableWordInfo;
    return this;
  }

  /**
   * Required. The language of the supplied audio. Dialogflow does not do translations. See
   * [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of
   * the currently supported language codes. Note that queries in the same session do not
   * necessarily need to specify the same language. If not set, the language is inferred from the
   * ConversationProfile.stt_config.
   * @return value or {@code null} for none
   */
  public java.lang.String getLanguageCode() {
    return languageCode;
  }

  /**
   * Required. The language of the supplied audio. Dialogflow does not do translations. See
   * [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of
   * the currently supported language codes. Note that queries in the same session do not
   * necessarily need to specify the same language. If not set, the language is inferred from the
   * ConversationProfile.stt_config.
   * @param languageCode languageCode or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setLanguageCode(java.lang.String languageCode) {
    this.languageCode = languageCode;
    return this;
  }

  /**
   * Optional. Which Speech model to select for the given request. For more information, see [Speech
   * models](https://cloud.google.com/dialogflow/es/docs/speech-models).
   * @return value or {@code null} for none
   */
  public java.lang.String getModel() {
    return model;
  }

  /**
   * Optional. Which Speech model to select for the given request. For more information, see [Speech
   * models](https://cloud.google.com/dialogflow/es/docs/speech-models).
   * @param model model or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setModel(java.lang.String model) {
    this.model = model;
    return this;
  }

  /**
   * Which variant of the Speech model to use.
   * @return value or {@code null} for none
   */
  public java.lang.String getModelVariant() {
    return modelVariant;
  }

  /**
   * Which variant of the Speech model to use.
   * @param modelVariant modelVariant or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setModelVariant(java.lang.String modelVariant) {
    this.modelVariant = modelVariant;
    return this;
  }

  /**
   * If `true`, the request will opt out for STT conformer model migration. This field will be
   * deprecated once force migration takes place in June 2024. Please refer to [Dialogflow ES Speech
   * model migration](https://cloud.google.com/dialogflow/es/docs/speech-model-migration).
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getOptOutConformerModelMigration() {
    return optOutConformerModelMigration;
  }

  /**
   * If `true`, the request will opt out for STT conformer model migration. This field will be
   * deprecated once force migration takes place in June 2024. Please refer to [Dialogflow ES Speech
   * model migration](https://cloud.google.com/dialogflow/es/docs/speech-model-migration).
   * @param optOutConformerModelMigration optOutConformerModelMigration or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setOptOutConformerModelMigration(java.lang.Boolean optOutConformerModelMigration) {
    this.optOutConformerModelMigration = optOutConformerModelMigration;
    return this;
  }

  /**
   * A list of strings containing words and phrases that the speech recognizer should recognize with
   * higher likelihood. See [the Cloud Speech documentation](https://cloud.google.com/speech-to-
   * text/docs/basics#phrase-hints) for more details. This field is deprecated. Please use
   * [`speech_contexts`]() instead. If you specify both [`phrase_hints`]() and
   * [`speech_contexts`](), Dialogflow will treat the [`phrase_hints`]() as a single additional
   * [`SpeechContext`]().
   * @return value or {@code null} for none
   */
  public java.util.List<java.lang.String> getPhraseHints() {
    return phraseHints;
  }

  /**
   * A list of strings containing words and phrases that the speech recognizer should recognize with
   * higher likelihood. See [the Cloud Speech documentation](https://cloud.google.com/speech-to-
   * text/docs/basics#phrase-hints) for more details. This field is deprecated. Please use
   * [`speech_contexts`]() instead. If you specify both [`phrase_hints`]() and
   * [`speech_contexts`](), Dialogflow will treat the [`phrase_hints`]() as a single additional
   * [`SpeechContext`]().
   * @param phraseHints phraseHints or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setPhraseHints(java.util.List<java.lang.String> phraseHints) {
    this.phraseHints = phraseHints;
    return this;
  }

  /**
   * A collection of phrase set resources to use for speech adaptation.
   * @return value or {@code null} for none
   */
  public java.util.List<java.lang.String> getPhraseSets() {
    return phraseSets;
  }

  /**
   * A collection of phrase set resources to use for speech adaptation.
   * @param phraseSets phraseSets or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setPhraseSets(java.util.List<java.lang.String> phraseSets) {
    this.phraseSets = phraseSets;
    return this;
  }

  /**
   * Required. Sample rate (in Hertz) of the audio content sent in the query. Refer to [Cloud Speech
   * API documentation](https://cloud.google.com/speech-to-text/docs/basics) for more details.
   * @return value or {@code null} for none
   */
  public java.lang.Integer getSampleRateHertz() {
    return sampleRateHertz;
  }

  /**
   * Required. Sample rate (in Hertz) of the audio content sent in the query. Refer to [Cloud Speech
   * API documentation](https://cloud.google.com/speech-to-text/docs/basics) for more details.
   * @param sampleRateHertz sampleRateHertz or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setSampleRateHertz(java.lang.Integer sampleRateHertz) {
    this.sampleRateHertz = sampleRateHertz;
    return this;
  }

  /**
   * If `false` (default), recognition does not cease until the client closes the stream. If `true`,
   * the recognizer will detect a single spoken utterance in input audio. Recognition ceases when it
   * detects the audio's voice has stopped or paused. In this case, once a detected intent is
   * received, the client should close the stream and start a new request with a new stream as
   * needed. Note: This setting is relevant only for streaming methods. Note: When specified,
   * InputAudioConfig.single_utterance takes precedence over
   * StreamingDetectIntentRequest.single_utterance.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getSingleUtterance() {
    return singleUtterance;
  }

  /**
   * If `false` (default), recognition does not cease until the client closes the stream. If `true`,
   * the recognizer will detect a single spoken utterance in input audio. Recognition ceases when it
   * detects the audio's voice has stopped or paused. In this case, once a detected intent is
   * received, the client should close the stream and start a new request with a new stream as
   * needed. Note: This setting is relevant only for streaming methods. Note: When specified,
   * InputAudioConfig.single_utterance takes precedence over
   * StreamingDetectIntentRequest.single_utterance.
   * @param singleUtterance singleUtterance or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setSingleUtterance(java.lang.Boolean singleUtterance) {
    this.singleUtterance = singleUtterance;
    return this;
  }

  /**
   * Context information to assist speech recognition. See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints) for more
   * details.
   * @return value or {@code null} for none
   */
  public java.util.List<GoogleCloudDialogflowV2beta1SpeechContext> getSpeechContexts() {
    return speechContexts;
  }

  /**
   * Context information to assist speech recognition. See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints) for more
   * details.
   * @param speechContexts speechContexts or {@code null} for none
   */
  public GoogleCloudDialogflowV2beta1InputAudioConfig setSpeechContexts(java.util.List<GoogleCloudDialogflowV2beta1SpeechContext> speechContexts) {
    this.speechContexts = speechContexts;
    return this;
  }

  @Override
  public GoogleCloudDialogflowV2beta1InputAudioConfig set(String fieldName, Object value) {
    return (GoogleCloudDialogflowV2beta1InputAudioConfig) super.set(fieldName, value);
  }

  @Override
  public GoogleCloudDialogflowV2beta1InputAudioConfig clone() {
    return (GoogleCloudDialogflowV2beta1InputAudioConfig) super.clone();
  }

}
