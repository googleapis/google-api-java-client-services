/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.aiplatform.v1.model;

/**
 * The Evalution configuration used for the evaluation run.
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the Vertex AI API. For a detailed explanation see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class GoogleCloudAiplatformV1EvaluationRunEvaluationConfig extends com.google.api.client.json.GenericJson {

  /**
   * Optional. The autorater config for the evaluation run.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1EvaluationRunEvaluationConfigAutoraterConfig autoraterConfig;

  /**
   * Required. The metrics to be calculated in the evaluation run.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<GoogleCloudAiplatformV1EvaluationRunMetric> metrics;

  /**
   * Optional. The output config for the evaluation run.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1EvaluationRunEvaluationConfigOutputConfig outputConfig;

  /**
   * The prompt template used for inference. The values for variables in the prompt template are
   * defined in EvaluationItem.EvaluationPrompt.PromptTemplateData.values.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private GoogleCloudAiplatformV1EvaluationRunEvaluationConfigPromptTemplate promptTemplate;

  /**
   * Optional. The rubric configs for the evaluation run. They are used to generate rubrics which
   * can be used by rubric-based metrics. Multiple rubric configs can be specified for rubric
   * generation but only one rubric config can be used for a rubric-based metric. If more than one
   * rubric config is provided, the evaluation metric must specify a rubric group key. Note that if
   * a generation spec is specified on both a rubric config and an evaluation metric, the rubrics
   * generated for the metric will be used for evaluation.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<GoogleCloudAiplatformV1EvaluationRubricConfig> rubricConfigs;

  static {
    // hack to force ProGuard to consider GoogleCloudAiplatformV1EvaluationRubricConfig used, since otherwise it would be stripped out
    // see https://github.com/google/google-api-java-client/issues/543
    com.google.api.client.util.Data.nullOf(GoogleCloudAiplatformV1EvaluationRubricConfig.class);
  }

  /**
   * Optional. The autorater config for the evaluation run.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfigAutoraterConfig getAutoraterConfig() {
    return autoraterConfig;
  }

  /**
   * Optional. The autorater config for the evaluation run.
   * @param autoraterConfig autoraterConfig or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig setAutoraterConfig(GoogleCloudAiplatformV1EvaluationRunEvaluationConfigAutoraterConfig autoraterConfig) {
    this.autoraterConfig = autoraterConfig;
    return this;
  }

  /**
   * Required. The metrics to be calculated in the evaluation run.
   * @return value or {@code null} for none
   */
  public java.util.List<GoogleCloudAiplatformV1EvaluationRunMetric> getMetrics() {
    return metrics;
  }

  /**
   * Required. The metrics to be calculated in the evaluation run.
   * @param metrics metrics or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig setMetrics(java.util.List<GoogleCloudAiplatformV1EvaluationRunMetric> metrics) {
    this.metrics = metrics;
    return this;
  }

  /**
   * Optional. The output config for the evaluation run.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfigOutputConfig getOutputConfig() {
    return outputConfig;
  }

  /**
   * Optional. The output config for the evaluation run.
   * @param outputConfig outputConfig or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig setOutputConfig(GoogleCloudAiplatformV1EvaluationRunEvaluationConfigOutputConfig outputConfig) {
    this.outputConfig = outputConfig;
    return this;
  }

  /**
   * The prompt template used for inference. The values for variables in the prompt template are
   * defined in EvaluationItem.EvaluationPrompt.PromptTemplateData.values.
   * @return value or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfigPromptTemplate getPromptTemplate() {
    return promptTemplate;
  }

  /**
   * The prompt template used for inference. The values for variables in the prompt template are
   * defined in EvaluationItem.EvaluationPrompt.PromptTemplateData.values.
   * @param promptTemplate promptTemplate or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig setPromptTemplate(GoogleCloudAiplatformV1EvaluationRunEvaluationConfigPromptTemplate promptTemplate) {
    this.promptTemplate = promptTemplate;
    return this;
  }

  /**
   * Optional. The rubric configs for the evaluation run. They are used to generate rubrics which
   * can be used by rubric-based metrics. Multiple rubric configs can be specified for rubric
   * generation but only one rubric config can be used for a rubric-based metric. If more than one
   * rubric config is provided, the evaluation metric must specify a rubric group key. Note that if
   * a generation spec is specified on both a rubric config and an evaluation metric, the rubrics
   * generated for the metric will be used for evaluation.
   * @return value or {@code null} for none
   */
  public java.util.List<GoogleCloudAiplatformV1EvaluationRubricConfig> getRubricConfigs() {
    return rubricConfigs;
  }

  /**
   * Optional. The rubric configs for the evaluation run. They are used to generate rubrics which
   * can be used by rubric-based metrics. Multiple rubric configs can be specified for rubric
   * generation but only one rubric config can be used for a rubric-based metric. If more than one
   * rubric config is provided, the evaluation metric must specify a rubric group key. Note that if
   * a generation spec is specified on both a rubric config and an evaluation metric, the rubrics
   * generated for the metric will be used for evaluation.
   * @param rubricConfigs rubricConfigs or {@code null} for none
   */
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig setRubricConfigs(java.util.List<GoogleCloudAiplatformV1EvaluationRubricConfig> rubricConfigs) {
    this.rubricConfigs = rubricConfigs;
    return this;
  }

  @Override
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig set(String fieldName, Object value) {
    return (GoogleCloudAiplatformV1EvaluationRunEvaluationConfig) super.set(fieldName, value);
  }

  @Override
  public GoogleCloudAiplatformV1EvaluationRunEvaluationConfig clone() {
    return (GoogleCloudAiplatformV1EvaluationRunEvaluationConfig) super.clone();
  }

}
