/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.contentwarehouse.v1.model;

/**
 * Next Tag: 52
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the Document AI Warehouse API. For a detailed explanation
 * see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class ImageRepositoryContentBasedVideoMetadata extends com.google.api.client.json.GenericJson {

  /**
   * A hash of the video bytes used as a key to Amarna's video_metadata table.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String amarnaDocid;

  /**
   * Timestamp of the last successful Ares classification request.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private String aresClassificationRequestTimestamp;

  /**
   * Both audio- and audio-video-files are treated as videos during indexing (whether they share a
   * container format, like .mp4, or not, like .mp3). This bool indicates that there's no video
   * track, just an audio track.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Boolean audioOnly;

  /**
   * Transcript generated from Cloud Speech API
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryAmarnaCloudSpeechSignals cloudSpeechSignals;

  /**
   * Video Understanding Golden features. (go/amarna-video-signals#golden-signals) Note: Golden6
   * features (names matching "video_*") are DEPRECATED. Please migrate to Golden7
   * ("VideoFeatures.*"). For more context, see go/golden7/migrating-from-golden6 and go/amarna-
   * golden-feature-tracker. Signals popluated in Raffia cdoc.doc_videos are configured in
   * cs/symbol:AMARNA_EXPORTED_GOLDEN7_FEATURES.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private DrishtiFeatureSetData featureSetData;

  /**
   * Frame-level Starburst embeddings. They are IE only signals for short videos initially and will
   * be supported for all videos later. (go/frame-level-sbv5-on-ie)
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryFrameLevelStarburstEmbeddings frameLevelStarburstEmbeddings;

  /**
   * Golden7 video-level people features. (go/ypf-video-features)
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private DrishtiFeatureSetData golden7SoapboxSummary;

  /**
   * Information on frame-level people feature blob. (go/vpf-frame-features)
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryAmarnaSignalsBlobInfo golden7SoapboxTracksBlobInfo;

  /**
   * Metadata related to Inline playback on the Interest Feed. This field is filled by Hamilton.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoCrawlVideoInlinePlaybackMetadata inlinePlayback;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoTimedtextS4ALIResults languageIdentification;

  /**
   * Legos results
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoLegosLegosAnnotationsSets legosAnnotationData;

  /**
   * LMS preview frame perdocs. Timestamps of the frame perdocs are from the original video, not
   * from the preview.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryFramePerdocs lmsPreviewFramePerdocs;

  /**
   * When Transcode itag 140 is requested, MediaAnalyzer (as the part of Viper graph) generates
   * audio info including loudness_data, which is then published to Streamer. For Audio news client,
   * we extract this loudness data from Streamer to this field.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoStorageLoudnessData loudnessData;

  /**
   * Information about the media file, such as duration, resolution, and detail about each
   * audio/video stream. Note that it contains no PII.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoMediaInfo mediaInfo;

  /**
   * multi_thumbnails_frame_perdocs contains perdocs(go/vss-signals#perdoc) for all frame thumbnails
   * generated by multiple frames per minutes. See more details in go/multiple-thumbnails-per-
   * minutes.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryFramePerdocs multiThumbnailsFramePerdocs;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageData representativeFrameData;

  /**
   * Trnascript generated through AMARNA_CLOUD_SPEECH asset in Venom. Note that AMARNA_CLOUD_SPEECH
   * uses S3 as the speech engine backend, similar to YT caption's SPEECH_RECOGNIZER asset. However,
   * they may use different S3 models.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryAmarnaCloudSpeechSignals s3Asr;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryS3LangIdSignals s3LanguageIdentification;

  /**
   * Contains SafeSearch video classification outputs which are vertical_name/float pairs.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private SafesearchVideoContentSignals safesearchVideoContentSignals;

  /**
   * 64 bit docid used for retrieving video previews.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.math.BigInteger searchDocid;

  /**
   * Amarna signals blob that contains large-size signals like VCA frame-level signals.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryAmarnaSignalsBlob signalsBlob;

  /**
   * Information for the amarna signals blob.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryAmarnaSignalsBlobInfo signalsBlobInfo;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private IndexingSpeechSpeechPropertiesProto speechProperties;

  /**
   * Thumbnail quality score predict how visual pleasing a thumbnail is, based on the model trained
   * with deep neural networks.(go/thumb_features_dd) Note the signal currently only available for
   * Youtube videos.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoThumbnailsThumbnailScore thumbnailQualityScore;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoPipelineViperThumbnailerColumnData thumbnailerData;

  /**
   * Metadata about each transcode requested.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<ImageRepositoryApiItagSpecificMetadata> transcodeMetadata;

  static {
    // hack to force ProGuard to consider ImageRepositoryApiItagSpecificMetadata used, since otherwise it would be stripped out
    // see https://github.com/google/google-api-java-client/issues/543
    com.google.api.client.util.Data.nullOf(ImageRepositoryApiItagSpecificMetadata.class);
  }

  /**
   * Speech related metadata The transcript_asr field is generated from the YT caption's
   * SPEECH_RECOGNIZER asset. We strongly recommend to use s3_asr instead of transcript_asr as of
   * 2024. Media Solutions team owns s3_asr and provides more flexibility with ASR features for our
   * client needs, whereas the underlying engine of the transcript_asr field is owned by Youtube,
   * and we do not have control over.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private PseudoVideoData transcriptAsr;

  /**
   * Data about whether or not the video was truncated.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryFileTruncationInfo truncationInfo;

  /**
   * If set, video has been deleted using the deletion service (MediaDeletionService).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryUnwantedContent unwantedContent;

  /**
   * The video id in the venom pipeline for STAMP purposes. DEPRECATED: Use transcode_metadata or
   * venom_processing_info instead, which includes the ID and contains information for all clients.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String venomId;

  /**
   * Information about the video's status in Venom, including IDs and processing times.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryVenomProcessingInfo venomProcessingInfo;

  /**
   * Video anchor sets hold set of anchors with multiple anchor types and sequence of VideoAnchor
   * which contains metadata about the anchor, such as thumbnail, perdoc data.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoContentSearchVideoAnchorSets videoAnchorSet;

  /**
   * Set from the video header if truncated, or is the verified length if completely crawled.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Double videoDurationSec;

  /**
   * The video porn confidence score extracted from Whisper featureSet: "video_labels:whisper_v3",
   * with CR2 label: "/cr2/1".
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Float videoPornScore;

  /**
   * The video porn confidence score extracted from WhisperV4 featureSet:
   * "VideoFeatures.whisper_v4_labels", with CR2 label: "/tns/porn".
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Float videoPornScoreV4;

  /**
   * video_preview_bytes is only exported as virtual dataset by IE VideoUnderstanding and should not
   * be persisted. It will be used by downstream IE functions to push for serving.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<ImageRepositoryVideoPreviewsVideoPreview> videoPreviewBytes;

  /**
   * video_previews contain the preview metadata but no bytes. It exits for IE and non-IE cases.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<ImageBaseVideoPreviewMetadata> videoPreviews;

  static {
    // hack to force ProGuard to consider ImageBaseVideoPreviewMetadata used, since otherwise it would be stripped out
    // see https://github.com/google/google-api-java-client/issues/543
    com.google.api.client.util.Data.nullOf(ImageBaseVideoPreviewMetadata.class);
  }

  /**
   * Deprecated, please use media_info.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoPipelineViperVSIColumnData videoStreamInfo;

  /**
   * VideoTranscriptAnnotations holds sentence segmented text and timing information to be used for
   * VideoAnswers (go/video-answers). Note that only punctuated_transcript, timing_info, and lang
   * field are filled, and other fields will be filled in the later stage.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private QualityWebanswersVideoTranscriptAnnotations videoTranscriptAnnotations;

  /**
   * Contains lists of reasons why YT videos were filtered from specific processing.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private ImageRepositoryYoutubeProcessingFilter youtubeProcessingFilter;

  /**
   * A hash of the video bytes used as a key to Amarna's video_metadata table.
   * @return value or {@code null} for none
   */
  public java.lang.String getAmarnaDocid() {
    return amarnaDocid;
  }

  /**
   * A hash of the video bytes used as a key to Amarna's video_metadata table.
   * @param amarnaDocid amarnaDocid or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setAmarnaDocid(java.lang.String amarnaDocid) {
    this.amarnaDocid = amarnaDocid;
    return this;
  }

  /**
   * Timestamp of the last successful Ares classification request.
   * @return value or {@code null} for none
   */
  public String getAresClassificationRequestTimestamp() {
    return aresClassificationRequestTimestamp;
  }

  /**
   * Timestamp of the last successful Ares classification request.
   * @param aresClassificationRequestTimestamp aresClassificationRequestTimestamp or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setAresClassificationRequestTimestamp(String aresClassificationRequestTimestamp) {
    this.aresClassificationRequestTimestamp = aresClassificationRequestTimestamp;
    return this;
  }

  /**
   * Both audio- and audio-video-files are treated as videos during indexing (whether they share a
   * container format, like .mp4, or not, like .mp3). This bool indicates that there's no video
   * track, just an audio track.
   * @return value or {@code null} for none
   */
  public java.lang.Boolean getAudioOnly() {
    return audioOnly;
  }

  /**
   * Both audio- and audio-video-files are treated as videos during indexing (whether they share a
   * container format, like .mp4, or not, like .mp3). This bool indicates that there's no video
   * track, just an audio track.
   * @param audioOnly audioOnly or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setAudioOnly(java.lang.Boolean audioOnly) {
    this.audioOnly = audioOnly;
    return this;
  }

  /**
   * Transcript generated from Cloud Speech API
   * @return value or {@code null} for none
   */
  public ImageRepositoryAmarnaCloudSpeechSignals getCloudSpeechSignals() {
    return cloudSpeechSignals;
  }

  /**
   * Transcript generated from Cloud Speech API
   * @param cloudSpeechSignals cloudSpeechSignals or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setCloudSpeechSignals(ImageRepositoryAmarnaCloudSpeechSignals cloudSpeechSignals) {
    this.cloudSpeechSignals = cloudSpeechSignals;
    return this;
  }

  /**
   * Video Understanding Golden features. (go/amarna-video-signals#golden-signals) Note: Golden6
   * features (names matching "video_*") are DEPRECATED. Please migrate to Golden7
   * ("VideoFeatures.*"). For more context, see go/golden7/migrating-from-golden6 and go/amarna-
   * golden-feature-tracker. Signals popluated in Raffia cdoc.doc_videos are configured in
   * cs/symbol:AMARNA_EXPORTED_GOLDEN7_FEATURES.
   * @return value or {@code null} for none
   */
  public DrishtiFeatureSetData getFeatureSetData() {
    return featureSetData;
  }

  /**
   * Video Understanding Golden features. (go/amarna-video-signals#golden-signals) Note: Golden6
   * features (names matching "video_*") are DEPRECATED. Please migrate to Golden7
   * ("VideoFeatures.*"). For more context, see go/golden7/migrating-from-golden6 and go/amarna-
   * golden-feature-tracker. Signals popluated in Raffia cdoc.doc_videos are configured in
   * cs/symbol:AMARNA_EXPORTED_GOLDEN7_FEATURES.
   * @param featureSetData featureSetData or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setFeatureSetData(DrishtiFeatureSetData featureSetData) {
    this.featureSetData = featureSetData;
    return this;
  }

  /**
   * Frame-level Starburst embeddings. They are IE only signals for short videos initially and will
   * be supported for all videos later. (go/frame-level-sbv5-on-ie)
   * @return value or {@code null} for none
   */
  public ImageRepositoryFrameLevelStarburstEmbeddings getFrameLevelStarburstEmbeddings() {
    return frameLevelStarburstEmbeddings;
  }

  /**
   * Frame-level Starburst embeddings. They are IE only signals for short videos initially and will
   * be supported for all videos later. (go/frame-level-sbv5-on-ie)
   * @param frameLevelStarburstEmbeddings frameLevelStarburstEmbeddings or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setFrameLevelStarburstEmbeddings(ImageRepositoryFrameLevelStarburstEmbeddings frameLevelStarburstEmbeddings) {
    this.frameLevelStarburstEmbeddings = frameLevelStarburstEmbeddings;
    return this;
  }

  /**
   * Golden7 video-level people features. (go/ypf-video-features)
   * @return value or {@code null} for none
   */
  public DrishtiFeatureSetData getGolden7SoapboxSummary() {
    return golden7SoapboxSummary;
  }

  /**
   * Golden7 video-level people features. (go/ypf-video-features)
   * @param golden7SoapboxSummary golden7SoapboxSummary or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setGolden7SoapboxSummary(DrishtiFeatureSetData golden7SoapboxSummary) {
    this.golden7SoapboxSummary = golden7SoapboxSummary;
    return this;
  }

  /**
   * Information on frame-level people feature blob. (go/vpf-frame-features)
   * @return value or {@code null} for none
   */
  public ImageRepositoryAmarnaSignalsBlobInfo getGolden7SoapboxTracksBlobInfo() {
    return golden7SoapboxTracksBlobInfo;
  }

  /**
   * Information on frame-level people feature blob. (go/vpf-frame-features)
   * @param golden7SoapboxTracksBlobInfo golden7SoapboxTracksBlobInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setGolden7SoapboxTracksBlobInfo(ImageRepositoryAmarnaSignalsBlobInfo golden7SoapboxTracksBlobInfo) {
    this.golden7SoapboxTracksBlobInfo = golden7SoapboxTracksBlobInfo;
    return this;
  }

  /**
   * Metadata related to Inline playback on the Interest Feed. This field is filled by Hamilton.
   * @return value or {@code null} for none
   */
  public VideoCrawlVideoInlinePlaybackMetadata getInlinePlayback() {
    return inlinePlayback;
  }

  /**
   * Metadata related to Inline playback on the Interest Feed. This field is filled by Hamilton.
   * @param inlinePlayback inlinePlayback or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setInlinePlayback(VideoCrawlVideoInlinePlaybackMetadata inlinePlayback) {
    this.inlinePlayback = inlinePlayback;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public VideoTimedtextS4ALIResults getLanguageIdentification() {
    return languageIdentification;
  }

  /**
   * @param languageIdentification languageIdentification or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setLanguageIdentification(VideoTimedtextS4ALIResults languageIdentification) {
    this.languageIdentification = languageIdentification;
    return this;
  }

  /**
   * Legos results
   * @return value or {@code null} for none
   */
  public VideoLegosLegosAnnotationsSets getLegosAnnotationData() {
    return legosAnnotationData;
  }

  /**
   * Legos results
   * @param legosAnnotationData legosAnnotationData or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setLegosAnnotationData(VideoLegosLegosAnnotationsSets legosAnnotationData) {
    this.legosAnnotationData = legosAnnotationData;
    return this;
  }

  /**
   * LMS preview frame perdocs. Timestamps of the frame perdocs are from the original video, not
   * from the preview.
   * @return value or {@code null} for none
   */
  public ImageRepositoryFramePerdocs getLmsPreviewFramePerdocs() {
    return lmsPreviewFramePerdocs;
  }

  /**
   * LMS preview frame perdocs. Timestamps of the frame perdocs are from the original video, not
   * from the preview.
   * @param lmsPreviewFramePerdocs lmsPreviewFramePerdocs or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setLmsPreviewFramePerdocs(ImageRepositoryFramePerdocs lmsPreviewFramePerdocs) {
    this.lmsPreviewFramePerdocs = lmsPreviewFramePerdocs;
    return this;
  }

  /**
   * When Transcode itag 140 is requested, MediaAnalyzer (as the part of Viper graph) generates
   * audio info including loudness_data, which is then published to Streamer. For Audio news client,
   * we extract this loudness data from Streamer to this field.
   * @return value or {@code null} for none
   */
  public VideoStorageLoudnessData getLoudnessData() {
    return loudnessData;
  }

  /**
   * When Transcode itag 140 is requested, MediaAnalyzer (as the part of Viper graph) generates
   * audio info including loudness_data, which is then published to Streamer. For Audio news client,
   * we extract this loudness data from Streamer to this field.
   * @param loudnessData loudnessData or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setLoudnessData(VideoStorageLoudnessData loudnessData) {
    this.loudnessData = loudnessData;
    return this;
  }

  /**
   * Information about the media file, such as duration, resolution, and detail about each
   * audio/video stream. Note that it contains no PII.
   * @return value or {@code null} for none
   */
  public VideoMediaInfo getMediaInfo() {
    return mediaInfo;
  }

  /**
   * Information about the media file, such as duration, resolution, and detail about each
   * audio/video stream. Note that it contains no PII.
   * @param mediaInfo mediaInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setMediaInfo(VideoMediaInfo mediaInfo) {
    this.mediaInfo = mediaInfo;
    return this;
  }

  /**
   * multi_thumbnails_frame_perdocs contains perdocs(go/vss-signals#perdoc) for all frame thumbnails
   * generated by multiple frames per minutes. See more details in go/multiple-thumbnails-per-
   * minutes.
   * @return value or {@code null} for none
   */
  public ImageRepositoryFramePerdocs getMultiThumbnailsFramePerdocs() {
    return multiThumbnailsFramePerdocs;
  }

  /**
   * multi_thumbnails_frame_perdocs contains perdocs(go/vss-signals#perdoc) for all frame thumbnails
   * generated by multiple frames per minutes. See more details in go/multiple-thumbnails-per-
   * minutes.
   * @param multiThumbnailsFramePerdocs multiThumbnailsFramePerdocs or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setMultiThumbnailsFramePerdocs(ImageRepositoryFramePerdocs multiThumbnailsFramePerdocs) {
    this.multiThumbnailsFramePerdocs = multiThumbnailsFramePerdocs;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public ImageData getRepresentativeFrameData() {
    return representativeFrameData;
  }

  /**
   * @param representativeFrameData representativeFrameData or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setRepresentativeFrameData(ImageData representativeFrameData) {
    this.representativeFrameData = representativeFrameData;
    return this;
  }

  /**
   * Trnascript generated through AMARNA_CLOUD_SPEECH asset in Venom. Note that AMARNA_CLOUD_SPEECH
   * uses S3 as the speech engine backend, similar to YT caption's SPEECH_RECOGNIZER asset. However,
   * they may use different S3 models.
   * @return value or {@code null} for none
   */
  public ImageRepositoryAmarnaCloudSpeechSignals getS3Asr() {
    return s3Asr;
  }

  /**
   * Trnascript generated through AMARNA_CLOUD_SPEECH asset in Venom. Note that AMARNA_CLOUD_SPEECH
   * uses S3 as the speech engine backend, similar to YT caption's SPEECH_RECOGNIZER asset. However,
   * they may use different S3 models.
   * @param s3Asr s3Asr or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setS3Asr(ImageRepositoryAmarnaCloudSpeechSignals s3Asr) {
    this.s3Asr = s3Asr;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public ImageRepositoryS3LangIdSignals getS3LanguageIdentification() {
    return s3LanguageIdentification;
  }

  /**
   * @param s3LanguageIdentification s3LanguageIdentification or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setS3LanguageIdentification(ImageRepositoryS3LangIdSignals s3LanguageIdentification) {
    this.s3LanguageIdentification = s3LanguageIdentification;
    return this;
  }

  /**
   * Contains SafeSearch video classification outputs which are vertical_name/float pairs.
   * @return value or {@code null} for none
   */
  public SafesearchVideoContentSignals getSafesearchVideoContentSignals() {
    return safesearchVideoContentSignals;
  }

  /**
   * Contains SafeSearch video classification outputs which are vertical_name/float pairs.
   * @param safesearchVideoContentSignals safesearchVideoContentSignals or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setSafesearchVideoContentSignals(SafesearchVideoContentSignals safesearchVideoContentSignals) {
    this.safesearchVideoContentSignals = safesearchVideoContentSignals;
    return this;
  }

  /**
   * 64 bit docid used for retrieving video previews.
   * @return value or {@code null} for none
   */
  public java.math.BigInteger getSearchDocid() {
    return searchDocid;
  }

  /**
   * 64 bit docid used for retrieving video previews.
   * @param searchDocid searchDocid or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setSearchDocid(java.math.BigInteger searchDocid) {
    this.searchDocid = searchDocid;
    return this;
  }

  /**
   * Amarna signals blob that contains large-size signals like VCA frame-level signals.
   * @return value or {@code null} for none
   */
  public ImageRepositoryAmarnaSignalsBlob getSignalsBlob() {
    return signalsBlob;
  }

  /**
   * Amarna signals blob that contains large-size signals like VCA frame-level signals.
   * @param signalsBlob signalsBlob or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setSignalsBlob(ImageRepositoryAmarnaSignalsBlob signalsBlob) {
    this.signalsBlob = signalsBlob;
    return this;
  }

  /**
   * Information for the amarna signals blob.
   * @return value or {@code null} for none
   */
  public ImageRepositoryAmarnaSignalsBlobInfo getSignalsBlobInfo() {
    return signalsBlobInfo;
  }

  /**
   * Information for the amarna signals blob.
   * @param signalsBlobInfo signalsBlobInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setSignalsBlobInfo(ImageRepositoryAmarnaSignalsBlobInfo signalsBlobInfo) {
    this.signalsBlobInfo = signalsBlobInfo;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public IndexingSpeechSpeechPropertiesProto getSpeechProperties() {
    return speechProperties;
  }

  /**
   * @param speechProperties speechProperties or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setSpeechProperties(IndexingSpeechSpeechPropertiesProto speechProperties) {
    this.speechProperties = speechProperties;
    return this;
  }

  /**
   * Thumbnail quality score predict how visual pleasing a thumbnail is, based on the model trained
   * with deep neural networks.(go/thumb_features_dd) Note the signal currently only available for
   * Youtube videos.
   * @return value or {@code null} for none
   */
  public VideoThumbnailsThumbnailScore getThumbnailQualityScore() {
    return thumbnailQualityScore;
  }

  /**
   * Thumbnail quality score predict how visual pleasing a thumbnail is, based on the model trained
   * with deep neural networks.(go/thumb_features_dd) Note the signal currently only available for
   * Youtube videos.
   * @param thumbnailQualityScore thumbnailQualityScore or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setThumbnailQualityScore(VideoThumbnailsThumbnailScore thumbnailQualityScore) {
    this.thumbnailQualityScore = thumbnailQualityScore;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public VideoPipelineViperThumbnailerColumnData getThumbnailerData() {
    return thumbnailerData;
  }

  /**
   * @param thumbnailerData thumbnailerData or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setThumbnailerData(VideoPipelineViperThumbnailerColumnData thumbnailerData) {
    this.thumbnailerData = thumbnailerData;
    return this;
  }

  /**
   * Metadata about each transcode requested.
   * @return value or {@code null} for none
   */
  public java.util.List<ImageRepositoryApiItagSpecificMetadata> getTranscodeMetadata() {
    return transcodeMetadata;
  }

  /**
   * Metadata about each transcode requested.
   * @param transcodeMetadata transcodeMetadata or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setTranscodeMetadata(java.util.List<ImageRepositoryApiItagSpecificMetadata> transcodeMetadata) {
    this.transcodeMetadata = transcodeMetadata;
    return this;
  }

  /**
   * Speech related metadata The transcript_asr field is generated from the YT caption's
   * SPEECH_RECOGNIZER asset. We strongly recommend to use s3_asr instead of transcript_asr as of
   * 2024. Media Solutions team owns s3_asr and provides more flexibility with ASR features for our
   * client needs, whereas the underlying engine of the transcript_asr field is owned by Youtube,
   * and we do not have control over.
   * @return value or {@code null} for none
   */
  public PseudoVideoData getTranscriptAsr() {
    return transcriptAsr;
  }

  /**
   * Speech related metadata The transcript_asr field is generated from the YT caption's
   * SPEECH_RECOGNIZER asset. We strongly recommend to use s3_asr instead of transcript_asr as of
   * 2024. Media Solutions team owns s3_asr and provides more flexibility with ASR features for our
   * client needs, whereas the underlying engine of the transcript_asr field is owned by Youtube,
   * and we do not have control over.
   * @param transcriptAsr transcriptAsr or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setTranscriptAsr(PseudoVideoData transcriptAsr) {
    this.transcriptAsr = transcriptAsr;
    return this;
  }

  /**
   * Data about whether or not the video was truncated.
   * @return value or {@code null} for none
   */
  public ImageRepositoryFileTruncationInfo getTruncationInfo() {
    return truncationInfo;
  }

  /**
   * Data about whether or not the video was truncated.
   * @param truncationInfo truncationInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setTruncationInfo(ImageRepositoryFileTruncationInfo truncationInfo) {
    this.truncationInfo = truncationInfo;
    return this;
  }

  /**
   * If set, video has been deleted using the deletion service (MediaDeletionService).
   * @return value or {@code null} for none
   */
  public ImageRepositoryUnwantedContent getUnwantedContent() {
    return unwantedContent;
  }

  /**
   * If set, video has been deleted using the deletion service (MediaDeletionService).
   * @param unwantedContent unwantedContent or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setUnwantedContent(ImageRepositoryUnwantedContent unwantedContent) {
    this.unwantedContent = unwantedContent;
    return this;
  }

  /**
   * The video id in the venom pipeline for STAMP purposes. DEPRECATED: Use transcode_metadata or
   * venom_processing_info instead, which includes the ID and contains information for all clients.
   * @return value or {@code null} for none
   */
  public java.lang.String getVenomId() {
    return venomId;
  }

  /**
   * The video id in the venom pipeline for STAMP purposes. DEPRECATED: Use transcode_metadata or
   * venom_processing_info instead, which includes the ID and contains information for all clients.
   * @param venomId venomId or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVenomId(java.lang.String venomId) {
    this.venomId = venomId;
    return this;
  }

  /**
   * Information about the video's status in Venom, including IDs and processing times.
   * @return value or {@code null} for none
   */
  public ImageRepositoryVenomProcessingInfo getVenomProcessingInfo() {
    return venomProcessingInfo;
  }

  /**
   * Information about the video's status in Venom, including IDs and processing times.
   * @param venomProcessingInfo venomProcessingInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVenomProcessingInfo(ImageRepositoryVenomProcessingInfo venomProcessingInfo) {
    this.venomProcessingInfo = venomProcessingInfo;
    return this;
  }

  /**
   * Video anchor sets hold set of anchors with multiple anchor types and sequence of VideoAnchor
   * which contains metadata about the anchor, such as thumbnail, perdoc data.
   * @return value or {@code null} for none
   */
  public VideoContentSearchVideoAnchorSets getVideoAnchorSet() {
    return videoAnchorSet;
  }

  /**
   * Video anchor sets hold set of anchors with multiple anchor types and sequence of VideoAnchor
   * which contains metadata about the anchor, such as thumbnail, perdoc data.
   * @param videoAnchorSet videoAnchorSet or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoAnchorSet(VideoContentSearchVideoAnchorSets videoAnchorSet) {
    this.videoAnchorSet = videoAnchorSet;
    return this;
  }

  /**
   * Set from the video header if truncated, or is the verified length if completely crawled.
   * @return value or {@code null} for none
   */
  public java.lang.Double getVideoDurationSec() {
    return videoDurationSec;
  }

  /**
   * Set from the video header if truncated, or is the verified length if completely crawled.
   * @param videoDurationSec videoDurationSec or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoDurationSec(java.lang.Double videoDurationSec) {
    this.videoDurationSec = videoDurationSec;
    return this;
  }

  /**
   * The video porn confidence score extracted from Whisper featureSet: "video_labels:whisper_v3",
   * with CR2 label: "/cr2/1".
   * @return value or {@code null} for none
   */
  public java.lang.Float getVideoPornScore() {
    return videoPornScore;
  }

  /**
   * The video porn confidence score extracted from Whisper featureSet: "video_labels:whisper_v3",
   * with CR2 label: "/cr2/1".
   * @param videoPornScore videoPornScore or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoPornScore(java.lang.Float videoPornScore) {
    this.videoPornScore = videoPornScore;
    return this;
  }

  /**
   * The video porn confidence score extracted from WhisperV4 featureSet:
   * "VideoFeatures.whisper_v4_labels", with CR2 label: "/tns/porn".
   * @return value or {@code null} for none
   */
  public java.lang.Float getVideoPornScoreV4() {
    return videoPornScoreV4;
  }

  /**
   * The video porn confidence score extracted from WhisperV4 featureSet:
   * "VideoFeatures.whisper_v4_labels", with CR2 label: "/tns/porn".
   * @param videoPornScoreV4 videoPornScoreV4 or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoPornScoreV4(java.lang.Float videoPornScoreV4) {
    this.videoPornScoreV4 = videoPornScoreV4;
    return this;
  }

  /**
   * video_preview_bytes is only exported as virtual dataset by IE VideoUnderstanding and should not
   * be persisted. It will be used by downstream IE functions to push for serving.
   * @return value or {@code null} for none
   */
  public java.util.List<ImageRepositoryVideoPreviewsVideoPreview> getVideoPreviewBytes() {
    return videoPreviewBytes;
  }

  /**
   * video_preview_bytes is only exported as virtual dataset by IE VideoUnderstanding and should not
   * be persisted. It will be used by downstream IE functions to push for serving.
   * @param videoPreviewBytes videoPreviewBytes or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoPreviewBytes(java.util.List<ImageRepositoryVideoPreviewsVideoPreview> videoPreviewBytes) {
    this.videoPreviewBytes = videoPreviewBytes;
    return this;
  }

  /**
   * video_previews contain the preview metadata but no bytes. It exits for IE and non-IE cases.
   * @return value or {@code null} for none
   */
  public java.util.List<ImageBaseVideoPreviewMetadata> getVideoPreviews() {
    return videoPreviews;
  }

  /**
   * video_previews contain the preview metadata but no bytes. It exits for IE and non-IE cases.
   * @param videoPreviews videoPreviews or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoPreviews(java.util.List<ImageBaseVideoPreviewMetadata> videoPreviews) {
    this.videoPreviews = videoPreviews;
    return this;
  }

  /**
   * Deprecated, please use media_info.
   * @return value or {@code null} for none
   */
  public VideoPipelineViperVSIColumnData getVideoStreamInfo() {
    return videoStreamInfo;
  }

  /**
   * Deprecated, please use media_info.
   * @param videoStreamInfo videoStreamInfo or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoStreamInfo(VideoPipelineViperVSIColumnData videoStreamInfo) {
    this.videoStreamInfo = videoStreamInfo;
    return this;
  }

  /**
   * VideoTranscriptAnnotations holds sentence segmented text and timing information to be used for
   * VideoAnswers (go/video-answers). Note that only punctuated_transcript, timing_info, and lang
   * field are filled, and other fields will be filled in the later stage.
   * @return value or {@code null} for none
   */
  public QualityWebanswersVideoTranscriptAnnotations getVideoTranscriptAnnotations() {
    return videoTranscriptAnnotations;
  }

  /**
   * VideoTranscriptAnnotations holds sentence segmented text and timing information to be used for
   * VideoAnswers (go/video-answers). Note that only punctuated_transcript, timing_info, and lang
   * field are filled, and other fields will be filled in the later stage.
   * @param videoTranscriptAnnotations videoTranscriptAnnotations or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setVideoTranscriptAnnotations(QualityWebanswersVideoTranscriptAnnotations videoTranscriptAnnotations) {
    this.videoTranscriptAnnotations = videoTranscriptAnnotations;
    return this;
  }

  /**
   * Contains lists of reasons why YT videos were filtered from specific processing.
   * @return value or {@code null} for none
   */
  public ImageRepositoryYoutubeProcessingFilter getYoutubeProcessingFilter() {
    return youtubeProcessingFilter;
  }

  /**
   * Contains lists of reasons why YT videos were filtered from specific processing.
   * @param youtubeProcessingFilter youtubeProcessingFilter or {@code null} for none
   */
  public ImageRepositoryContentBasedVideoMetadata setYoutubeProcessingFilter(ImageRepositoryYoutubeProcessingFilter youtubeProcessingFilter) {
    this.youtubeProcessingFilter = youtubeProcessingFilter;
    return this;
  }

  @Override
  public ImageRepositoryContentBasedVideoMetadata set(String fieldName, Object value) {
    return (ImageRepositoryContentBasedVideoMetadata) super.set(fieldName, value);
  }

  @Override
  public ImageRepositoryContentBasedVideoMetadata clone() {
    return (ImageRepositoryContentBasedVideoMetadata) super.clone();
  }

}
