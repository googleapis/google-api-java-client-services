/*
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
 * in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the License
 * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing permissions and limitations under
 * the License.
 */
/*
 * This code was generated by https://github.com/googleapis/google-api-java-client-services/
 * Modify at your own risk.
 */

package com.google.api.services.contentwarehouse.v1.model;

/**
 * Next id: 25
 *
 * <p> This is the Java data model class that specifies how to parse/serialize into the JSON that is
 * transmitted over HTTP when working with the Document AI Warehouse API. For a detailed explanation
 * see:
 * <a href="https://developers.google.com/api-client-library/java/google-http-java-client/json">https://developers.google.com/api-client-library/java/google-http-java-client/json</a>
 * </p>
 *
 * @author Google, Inc.
 */
@SuppressWarnings("javadoc")
public final class VideoVideoStreamInfoAudioStream extends com.google.api.client.json.GenericJson {

  /**
   * Optional ambisonics metadata.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private VideoAmbisonicsAmbisonicsMetadata ambisonics;

  /**
   * audio bitrate in bits/s
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long bitrate;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<java.lang.String> channelPosition;

  /**
   * number of audio channels
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Integer channels;

  /**
   * some container allows for a clock discontinuity. In this case, the end_timestamp may not be the
   * correct DTS of the stream.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long clockDiscontinuityUs;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String codecFourcc;

  /**
   * Primary audio codec information
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String codecId;

  /**
   * RFC6381 Codec string.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String codecString;

  /**
   * Specifies the content_type of the audio stream as given in the metadata.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String contentType;

  /**
   * The bytes offset of the end of the first decodable packet.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long decodeOffset;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long endTimestamp;

  /**
   * audio frame size
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long frameSize;

  /**
   * Specifies the language of the audio stream as given in the metadata.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String language;

  /**
   * audio length in seconds Note that when the VSI is from users videos, it is not guaranteed to be
   * the same as transcode lengths and it could be 0 when the full VSI cannot compute the length
   * from the source header and timestamps (for example when header and timestamps are too broken).
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Double length;

  /**
   * Metadata for audio elementary stream;
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.util.List<VideoClipInfo> metadata;

  static {
    // hack to force ProGuard to consider VideoClipInfo used, since otherwise it would be stripped out
    // see https://github.com/google/google-api-java-client/issues/543
    com.google.api.client.util.Data.nullOf(VideoClipInfo.class);
  }

  /**
   * Number of audio frames.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long numberOfFrames;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.String profile;

  /**
   * audio sample rate
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long sampleRate;

  /**
   * Number of meaningful bits per decoded audio sample. This is an implicit conceptual meaning.
   * This is *NOT* the same as ffmpeg's internal sample format that is used when actually decoding
   * with ffmpeg.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key
  private java.lang.Integer sampleSize;

  /**
   * Start/end timestamps of audio in ms.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long startTimestamp;

  /**
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long streamCodecTag;

  /**
   * Index of the stream in the file. it is 0 based.
   * The value may be {@code null}.
   */
  @com.google.api.client.util.Key @com.google.api.client.json.JsonString
  private java.lang.Long streamIndex;

  /**
   * Optional ambisonics metadata.
   * @return value or {@code null} for none
   */
  public VideoAmbisonicsAmbisonicsMetadata getAmbisonics() {
    return ambisonics;
  }

  /**
   * Optional ambisonics metadata.
   * @param ambisonics ambisonics or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setAmbisonics(VideoAmbisonicsAmbisonicsMetadata ambisonics) {
    this.ambisonics = ambisonics;
    return this;
  }

  /**
   * audio bitrate in bits/s
   * @return value or {@code null} for none
   */
  public java.lang.Long getBitrate() {
    return bitrate;
  }

  /**
   * audio bitrate in bits/s
   * @param bitrate bitrate or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setBitrate(java.lang.Long bitrate) {
    this.bitrate = bitrate;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public java.util.List<java.lang.String> getChannelPosition() {
    return channelPosition;
  }

  /**
   * @param channelPosition channelPosition or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setChannelPosition(java.util.List<java.lang.String> channelPosition) {
    this.channelPosition = channelPosition;
    return this;
  }

  /**
   * number of audio channels
   * @return value or {@code null} for none
   */
  public java.lang.Integer getChannels() {
    return channels;
  }

  /**
   * number of audio channels
   * @param channels channels or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setChannels(java.lang.Integer channels) {
    this.channels = channels;
    return this;
  }

  /**
   * some container allows for a clock discontinuity. In this case, the end_timestamp may not be the
   * correct DTS of the stream.
   * @return value or {@code null} for none
   */
  public java.lang.Long getClockDiscontinuityUs() {
    return clockDiscontinuityUs;
  }

  /**
   * some container allows for a clock discontinuity. In this case, the end_timestamp may not be the
   * correct DTS of the stream.
   * @param clockDiscontinuityUs clockDiscontinuityUs or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setClockDiscontinuityUs(java.lang.Long clockDiscontinuityUs) {
    this.clockDiscontinuityUs = clockDiscontinuityUs;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public java.lang.String getCodecFourcc() {
    return codecFourcc;
  }

  /**
   * @param codecFourcc codecFourcc or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setCodecFourcc(java.lang.String codecFourcc) {
    this.codecFourcc = codecFourcc;
    return this;
  }

  /**
   * Primary audio codec information
   * @return value or {@code null} for none
   */
  public java.lang.String getCodecId() {
    return codecId;
  }

  /**
   * Primary audio codec information
   * @param codecId codecId or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setCodecId(java.lang.String codecId) {
    this.codecId = codecId;
    return this;
  }

  /**
   * RFC6381 Codec string.
   * @return value or {@code null} for none
   */
  public java.lang.String getCodecString() {
    return codecString;
  }

  /**
   * RFC6381 Codec string.
   * @param codecString codecString or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setCodecString(java.lang.String codecString) {
    this.codecString = codecString;
    return this;
  }

  /**
   * Specifies the content_type of the audio stream as given in the metadata.
   * @return value or {@code null} for none
   */
  public java.lang.String getContentType() {
    return contentType;
  }

  /**
   * Specifies the content_type of the audio stream as given in the metadata.
   * @param contentType contentType or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setContentType(java.lang.String contentType) {
    this.contentType = contentType;
    return this;
  }

  /**
   * The bytes offset of the end of the first decodable packet.
   * @return value or {@code null} for none
   */
  public java.lang.Long getDecodeOffset() {
    return decodeOffset;
  }

  /**
   * The bytes offset of the end of the first decodable packet.
   * @param decodeOffset decodeOffset or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setDecodeOffset(java.lang.Long decodeOffset) {
    this.decodeOffset = decodeOffset;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public java.lang.Long getEndTimestamp() {
    return endTimestamp;
  }

  /**
   * @param endTimestamp endTimestamp or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setEndTimestamp(java.lang.Long endTimestamp) {
    this.endTimestamp = endTimestamp;
    return this;
  }

  /**
   * audio frame size
   * @return value or {@code null} for none
   */
  public java.lang.Long getFrameSize() {
    return frameSize;
  }

  /**
   * audio frame size
   * @param frameSize frameSize or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setFrameSize(java.lang.Long frameSize) {
    this.frameSize = frameSize;
    return this;
  }

  /**
   * Specifies the language of the audio stream as given in the metadata.
   * @return value or {@code null} for none
   */
  public java.lang.String getLanguage() {
    return language;
  }

  /**
   * Specifies the language of the audio stream as given in the metadata.
   * @param language language or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setLanguage(java.lang.String language) {
    this.language = language;
    return this;
  }

  /**
   * audio length in seconds Note that when the VSI is from users videos, it is not guaranteed to be
   * the same as transcode lengths and it could be 0 when the full VSI cannot compute the length
   * from the source header and timestamps (for example when header and timestamps are too broken).
   * @return value or {@code null} for none
   */
  public java.lang.Double getLength() {
    return length;
  }

  /**
   * audio length in seconds Note that when the VSI is from users videos, it is not guaranteed to be
   * the same as transcode lengths and it could be 0 when the full VSI cannot compute the length
   * from the source header and timestamps (for example when header and timestamps are too broken).
   * @param length length or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setLength(java.lang.Double length) {
    this.length = length;
    return this;
  }

  /**
   * Metadata for audio elementary stream;
   * @return value or {@code null} for none
   */
  public java.util.List<VideoClipInfo> getMetadata() {
    return metadata;
  }

  /**
   * Metadata for audio elementary stream;
   * @param metadata metadata or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setMetadata(java.util.List<VideoClipInfo> metadata) {
    this.metadata = metadata;
    return this;
  }

  /**
   * Number of audio frames.
   * @return value or {@code null} for none
   */
  public java.lang.Long getNumberOfFrames() {
    return numberOfFrames;
  }

  /**
   * Number of audio frames.
   * @param numberOfFrames numberOfFrames or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setNumberOfFrames(java.lang.Long numberOfFrames) {
    this.numberOfFrames = numberOfFrames;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public java.lang.String getProfile() {
    return profile;
  }

  /**
   * @param profile profile or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setProfile(java.lang.String profile) {
    this.profile = profile;
    return this;
  }

  /**
   * audio sample rate
   * @return value or {@code null} for none
   */
  public java.lang.Long getSampleRate() {
    return sampleRate;
  }

  /**
   * audio sample rate
   * @param sampleRate sampleRate or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setSampleRate(java.lang.Long sampleRate) {
    this.sampleRate = sampleRate;
    return this;
  }

  /**
   * Number of meaningful bits per decoded audio sample. This is an implicit conceptual meaning.
   * This is *NOT* the same as ffmpeg's internal sample format that is used when actually decoding
   * with ffmpeg.
   * @return value or {@code null} for none
   */
  public java.lang.Integer getSampleSize() {
    return sampleSize;
  }

  /**
   * Number of meaningful bits per decoded audio sample. This is an implicit conceptual meaning.
   * This is *NOT* the same as ffmpeg's internal sample format that is used when actually decoding
   * with ffmpeg.
   * @param sampleSize sampleSize or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setSampleSize(java.lang.Integer sampleSize) {
    this.sampleSize = sampleSize;
    return this;
  }

  /**
   * Start/end timestamps of audio in ms.
   * @return value or {@code null} for none
   */
  public java.lang.Long getStartTimestamp() {
    return startTimestamp;
  }

  /**
   * Start/end timestamps of audio in ms.
   * @param startTimestamp startTimestamp or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setStartTimestamp(java.lang.Long startTimestamp) {
    this.startTimestamp = startTimestamp;
    return this;
  }

  /**
   * @return value or {@code null} for none
   */
  public java.lang.Long getStreamCodecTag() {
    return streamCodecTag;
  }

  /**
   * @param streamCodecTag streamCodecTag or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setStreamCodecTag(java.lang.Long streamCodecTag) {
    this.streamCodecTag = streamCodecTag;
    return this;
  }

  /**
   * Index of the stream in the file. it is 0 based.
   * @return value or {@code null} for none
   */
  public java.lang.Long getStreamIndex() {
    return streamIndex;
  }

  /**
   * Index of the stream in the file. it is 0 based.
   * @param streamIndex streamIndex or {@code null} for none
   */
  public VideoVideoStreamInfoAudioStream setStreamIndex(java.lang.Long streamIndex) {
    this.streamIndex = streamIndex;
    return this;
  }

  @Override
  public VideoVideoStreamInfoAudioStream set(String fieldName, Object value) {
    return (VideoVideoStreamInfoAudioStream) super.set(fieldName, value);
  }

  @Override
  public VideoVideoStreamInfoAudioStream clone() {
    return (VideoVideoStreamInfoAudioStream) super.clone();
  }

}
